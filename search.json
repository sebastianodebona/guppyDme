[{"path":"https://sebastianodebona.github.io/guppyDme/articles/DME-000_Tidy_data.html","id":"overwiew-setup","dir":"Articles","previous_headings":"","what":"Overwiew & setup","title":"Tidy the data","text":"vignette handles data obtain individual information across two recaptures, dispersal, habitat shift, growth.","code":"# loading necessary packages library(tidyverse) library(magrittr)  # this requires the package guppyDme to be installed. If the user wishes not to install the package, please comment out the \"library(guppyDme)\" line and run instead the lines commented out below  #### If you have the guppyDme package installed # loading package library(guppyDme)  # # If you do NOT wish to install the guppyDme package, please uncomment and run the following two lines of code, adding the package functions to the Global Environment and loading the data # source(file.path(here::here(), \"R\", \"package_functions.R\")) # load(file.path(here::here(), \"data\", \"DMEdata.rda\"))  # loading data data <- DMEdata str(data) ## tibble [2,930 × 21] (S3: tbl_df/tbl/data.frame) ##  $ processingDate: Date[1:2930], format: \"2018-03-19\" \"2018-03-19\" ... ##  $ captureDate   : Date[1:2930], format: \"2018-03-18\" \"2018-03-18\" ... ##  $ markID        : Factor w/ 2219 levels \"105K\",\"105Y\",..: 643 781 731 539 581 476 795 814 461 518 ... ##  $ tank          : chr [1:2930] \"1\" \"1\" \"1\" \"1\" ... ##  $ bag           : int [1:2930] NA NA NA NA NA NA NA NA NA NA ... ##  $ sex           : Factor w/ 4 levels \"B\",\"F\",\"J\",\"M\": 2 2 2 4 2 2 2 4 3 2 ... ##  $ SL            : chr [1:2930] \"21.29\" \"20.62\" \"17.38\" \"17.64\" ... ##  $ weight        : num [1:2930] 0.183 0.155 0.071 0.086 0.106 0.057 0.061 0.077 0.068 0.086 ... ##  $ stream        : Factor w/ 2 levels \"CAIGUAL\",\"TAYLOR\": 1 1 1 1 1 1 1 1 1 1 ... ##  $ streamID      : Factor w/ 4 levels \"CL1\",\"CL2\",\"TL\",..: 1 1 1 1 1 1 1 1 1 1 ... ##  $ location      : chr [1:2930] \"P10-15\" \"P10-15\" \"P10-15\" \"P10-15\" ... ##  $ habitat       : Factor w/ 5 levels \"A\",\"B\",\"C\",\"D\",..: 4 4 4 4 4 4 4 4 4 4 ... ##  $ treatment     : chr [1:2930] \"I\" \"I\" \"I\" \"I\" ... ##  $ releaseDate   : Date[1:2930], format: \"2018-03-21\" \"2018-03-21\" ... ##  $ markerID      : chr [1:2930] \"DKS\" \"DKS\" \"DKS\" \"DKS\" ... ##  $ recap         : int [1:2930] 0 0 0 0 0 0 0 0 0 0 ... ##  $ formaline     : int [1:2930] 0 0 0 0 0 0 0 0 0 0 ... ##  $ comments      : chr [1:2930] \"\" \"\" \"\" \"\" ... ##  $ patchID       : Factor w/ 33 levels \"B8.5-9\",\"N23-32\",..: 7 7 7 7 7 7 7 7 7 7 ... ##  $ isbabyMark    : logi [1:2930] FALSE FALSE FALSE FALSE FALSE FALSE ... ##  $ isCohort      : logi [1:2930] FALSE FALSE FALSE FALSE FALSE FALSE ... # including sex_stage variable and converting size into numeric data %<>%   mutate(SL = as.numeric(SL),          sex_stage = score_sexst(., f_threshold = 14.00, f_unit = \"SL\")) # I am here using the SL as a unit of threshold, since individuals preserved # in formaline don't have weight information  # checking which individuals are missing a capture location data %>%    filter(is.na(patchID)) ## # A tibble: 47 × 22 ##    processingDate captureDate markID tank    bag sex      SL weight stream ##    <date>         <date>      <fct>  <chr> <int> <fct> <dbl>  <dbl> <fct>  ##  1 2018-03-24     2018-03-22  1RX    21       NA J      18.8  0.106 TAYLOR ##  2 2018-03-24     2018-03-22  1RX    21       NA J      18.2  0.093 TAYLOR ##  3 2018-03-24     2018-03-22  1RX    21       NA M      18.7  0.096 TAYLOR ##  4 2018-03-24     2018-03-22  1RX    21       NA F      25.1  0.248 TAYLOR ##  5 2018-03-24     2018-03-22  1RX    21       NA F      25.6  0.193 TAYLOR ##  6 2018-03-24     2018-03-22  1R2K6B 21       NA F      28.0  0.382 TAYLOR ##  7 2018-03-24     2018-03-22  1RX    21       NA M      20.0  0.112 TAYLOR ##  8 2018-03-24     2018-03-22  1RX    21       NA F      14.2  0.051 TAYLOR ##  9 2018-03-24     2018-03-22  1RX    21       NA F      24.2  0.25  TAYLOR ## 10 2018-03-24     2018-03-22  1RX    21       NA F      23.5  0.256 TAYLOR ## # ℹ 37 more rows ## # ℹ 13 more variables: streamID <fct>, location <chr>, habitat <fct>, ## #   treatment <chr>, releaseDate <date>, markerID <chr>, recap <int>, ## #   formaline <int>, comments <chr>, patchID <fct>, isbabyMark <lgl>, ## #   isCohort <lgl>, sex_stage <chr> # these individuals belong to two bottles that were accidentally mixed during processing. # individuals in it were not included in the experiment"},{"path":"https://sebastianodebona.github.io/guppyDme/articles/DME-000_Tidy_data.html","id":"spreading-and-shrinking-the-data","dir":"Articles","previous_headings":"","what":"Spreading and shrinking the data","title":"Tidy the data","text":"analyse dispersal habitat change need transform dataset long wide format (spread), reducing recaptured individuals . 435 recapture events (732 adults captured). Let’s see many individuals per treatment dealing . far ’ve dealt adult individuals unique mark. cohort marks (.e. individuals 10 13 mm received single mark, assigning size cohort, pool habitat), need take different approach. Cohort marks unique marks, back-track information capture (, long 1mm error, habitat found ) based mark. ’ve done , can add information one concerning adults. things consider subsetting cohort marks. Individuals removed decreased density pool also marked cohort mark (\"1R\", \"1RX\", \"3R\" \"1R2R\"). ’ll need consider individuals. Moreover, cohort marks given individuals N treatment (natural untouched pools) added increased pool (E treatment) given pool-specific mark, individuals different habitats size classes sharing mark. cohort mark used one pool size class habitat combination. Let’s check whether true. can now filter away reused mark, extract pool, habitat, position, mean SL, together information match adults’. Similarly done adults, can extract data recaptures, merge capture data . don’t need remove mark yet, since inner merge marks already removed capture data (reused marks, removed individuals) dropped . now need careful, adding rows cohort individuals, variables cohort dataset. Now can add rows main dataset cr_data. ’s useful know pool-specific habitat patch individuals move . instance, individuals released specific treatment (control, increased, decreased) move different pool anther treatment. one necessary change avoid confusion. variable patch_0 extracted main dataset refer location individual captured. case extra-limital individuals introduced increased-density pool, course correspond location individuals released. , fact, increased density pool. Leaving patch_0 now cause us overestimate dispersal, considering dispersal event individuals artificially moved “PEX” increased density pool. problem, long exclude extra-limital individuals (treatment “E”) analysis, . just case, lets fix .","code":"captures <- data %>% # we are here selecting all individuals that are not babies, cohort or in TM   filter(recap == 0, !isbabyMark, !isCohort, streamID != \"TM\") %>%   select(markID, streamID, treatment, sex_stage_0 = sex_stage,          patch_0 = patchID, habitat_0 = habitat,          SL_0 = SL, weight_0 = weight, releaseDate, marker_0 = markerID)    recaptures <- data %>%   filter(recap == 1, !isbabyMark, !isCohort) %>%   select(markID,           patch_1 = patchID, habitat_1 = habitat, sex_stage_1 = sex_stage,          SL_1 = SL, weight_1 = weight, captureDate, marker_1 = markerID)  # merging, but keeping only markIDs that are shared among the two datasets # (only recaptured individuals) cr_data <- inner_join(captures, recaptures, by = \"markID\") str(cr_data) ## tibble [435 × 17] (S3: tbl_df/tbl/data.frame) ##  $ markID     : Factor w/ 2219 levels \"105K\",\"105Y\",..: 643 781 731 539 581 795 814 461 635 303 ... ##  $ streamID   : Factor w/ 4 levels \"CL1\",\"CL2\",\"TL\",..: 1 1 1 1 1 1 1 1 1 1 ... ##  $ treatment  : chr [1:435] \"I\" \"I\" \"I\" \"I\" ... ##  $ sex_stage_0: chr [1:435] \"F\" \"F\" \"F\" \"M\" ... ##  $ patch_0    : Factor w/ 33 levels \"B8.5-9\",\"N23-32\",..: 7 7 7 7 7 7 7 7 7 7 ... ##  $ habitat_0  : Factor w/ 5 levels \"A\",\"B\",\"C\",\"D\",..: 4 4 4 4 4 4 4 4 2 2 ... ##  $ SL_0       : num [1:435] 21.3 20.6 17.4 17.6 19 ... ##  $ weight_0   : num [1:435] 0.183 0.155 0.071 0.086 0.106 0.061 0.077 0.068 0.13 0.485 ... ##  $ releaseDate: Date[1:435], format: \"2018-03-21\" \"2018-03-21\" ... ##  $ marker_0   : chr [1:435] \"DKS\" \"DKS\" \"DKS\" \"DKS\" ... ##  $ patch_1    : Factor w/ 33 levels \"B8.5-9\",\"N23-32\",..: 7 7 7 7 7 7 29 10 7 7 ... ##  $ habitat_1  : Factor w/ 5 levels \"A\",\"B\",\"C\",\"D\",..: 1 3 1 3 3 3 NA 3 3 1 ... ##  $ sex_stage_1: chr [1:435] \"F\" \"F\" \"F\" \"M\" ... ##  $ SL_1       : num [1:435] 22.4 19.3 17.2 17.5 19.7 ... ##  $ weight_1   : num [1:435] 0.158 NA NA 0.099 0.131 NA 0.065 0.102 0.156 NA ... ##  $ captureDate: Date[1:435], format: \"2018-04-19\" \"2018-04-19\" ... ##  $ marker_1   : chr [1:435] \"DKS\" \"SDB\" \"SDB\" \"DKS\" ... cr_data %>%   group_by(treatment) %>%   count() ## # A tibble: 6 × 2 ## # Groups:   treatment [6] ##   treatment     n ##   <chr>     <int> ## 1 C           159 ## 2 D            51 ## 3 E            50 ## 4 I           103 ## 5 N            70 ## 6 NA            2 cr_data %>%   filter(is.na(treatment)) ## # A tibble: 2 × 17 ##   markID streamID treatment sex_stage_0 patch_0 habitat_0  SL_0 weight_0 ##   <fct>  <fct>    <chr>     <chr>       <fct>   <fct>     <dbl>    <dbl> ## 1 5V7Y   CL1      NA        I           PEX-CL  NA         15.2    0.057 ## 2 6Y8W   CL1      NA        I           PEX-CL  NA         17.1    0.087 ## # ℹ 9 more variables: releaseDate <date>, marker_0 <chr>, patch_1 <fct>, ## #   habitat_1 <fct>, sex_stage_1 <chr>, SL_1 <dbl>, weight_1 <dbl>, ## #   captureDate <date>, marker_1 <chr> # first, extracting information on capture cohort_captures <- data %>%   filter(recap == 0,           isCohort, !(markID %in% c(\"1R\", \"1RX\", \"1R2R\", \"3R\")),          streamID != \"TM\",          !(treatment %in% c(\"R\", \"E\", \"N\")) ) reused_marks <- cohort_captures %>%   # dividing in categorical size classes   mutate(size_class = cut(as.numeric(SL), breaks = c(10, 11, 12, 13))) %>%   group_by(markID, stream, patchID, habitat, size_class) %>%   summarise() %>%   group_by(markID, stream) %>%   # the following code pulls out the markID which are repeated for more than one   # habitat-size-pool combination in a stream.   nest() %>%   mutate(n = (map(data, nrow))) %>%   filter(n > 1) %>%   select(markID, stream) %T>%   print ## `summarise()` has grouped output by 'markID', 'stream', 'patchID', 'habitat'. ## You can override using the `.groups` argument. ## # A tibble: 1 × 2 ## # Groups:   markID, stream [1] ##   markID stream ##   <fct>  <fct>  ## 1 2P     TAYLOR mean_SL <- cohort_captures %>%   filter(!(markID %in% reused_marks$markID & stream %in% reused_marks$stream)) %>%   group_by(markID, streamID) %>%   summarise(SL_0 = mean(as.numeric(SL), na.rm = T)) ## `summarise()` has grouped output by 'markID'. You can override using the ## `.groups` argument. NROW = nrow(mean_SL)  cohort_captures %<>%   # removing reused marks   filter(!(markID %in% reused_marks$markID & stream %in% reused_marks$stream)) %>%   # extracting only unique combinations (which should match the mean_SL)   distinct(markID, streamID, stream, treatment, sex_stage_0 = sex_stage,          patch_0 = patchID, habitat_0 = habitat, releaseDate) # checking whether we did obtain only unique rows, matching mean_SL stopifnot(nrow(cohort_captures) == NROW) # merging (and adding a column of NAs for the initial weight) cohort_captures <- left_join(cohort_captures, mean_SL) %>%   add_column(weight_0 = NA) ## Joining with `by = join_by(markID, streamID)` cohort_recaptures <- data %>%   filter(recap == 1, isCohort) %>%   select(markID,           stream, patch_1 = patchID, habitat_1 = habitat, sex_stage_1 = sex_stage,          SL_1 = SL, weight_1 = weight, captureDate)  # merging cr_cohorts <- inner_join(cohort_captures, cohort_recaptures, by = c(\"markID\", \"stream\")) # checking if any variable that is present in cr_data is missing # in cr_cohorts table(is.na(match(colnames(cr_data), colnames(cr_cohorts)))) ##  ## FALSE  TRUE  ##    15     2 # no variables missing  # now checking if there are extra variables in cr_cohorts that are not in cr_data extra_var <- colnames(cr_cohorts)[is.na(match(colnames(cr_cohorts), colnames(cr_data)))]  # before proceeding I need to remove this variable(s) cr_cohorts %<>%   select(-all_of(extra_var)) cr_data <- bind_rows(cr_data, cr_cohorts) # for the starting pool is fine, since the pool treatment can be # derived from the individual treatment cr_data %<>%   mutate(pool_treat_0 = str_replace_all(treatment,                                         c(\"C\" = \"control\",                                           \"D\" = \"decreased\",                                           \"I\" = \"increased\",                                           \"E\" = \"increased\",                                           \"N\" = \"natural\")),          pool_treat_0 = ifelse(is.na(pool_treat_0), \"natural\", pool_treat_0))  # for the arrival pool is a little trickier. I need to create # a key that matches pools to their treatment type. pool_to_treat <- as_tibble(   cr_data %>%     filter(treatment %in% c(\"C\", \"I\", \"D\")) %>%     group_by(streamID, patch_0, treatment) %>%     summarise()) ## `summarise()` has grouped output by 'streamID', 'patch_0'. You can override ## using the `.groups` argument. # Now I can transform the treatment into its spelled-out form # and add it to the cr_data for the recapture pools ptt_table <- pool_to_treat %>%   mutate(pool_treat_1 = str_replace_all(treatment,                                         c(\"C\" = \"control\",                                           \"D\" = \"decreased\",                                           \"I\" = \"increased\"))) %>%   ungroup() %>%   select(patch_1 = patch_0, pool_treat_1) # I here removed treatment and renamed the pool (0 to 1) to ease the merge # pool_0 was used to extract the type of treatment, by now I need to apply # that treatment to the arrival pool (1) # I also removed streamID, to account for fish that moved from CL1 to CL2. # pool names cannot be confounded between streams in any case.  # merging pool_treat_1 info and replacing NAs (all that is not control, increased # or decreased) with \"natural\" cr_data %<>%   left_join(ptt_table) %>%   mutate(pool_treat_1 = ifelse(is.na(pool_treat_1), \"natural\", pool_treat_1)) ## Joining with `by = join_by(patch_1)` # checking which are the increased pools pool_to_treat %>%   filter(treatment == \"I\") ## # A tibble: 3 × 3 ##   streamID patch_0  treatment ##   <fct>    <fct>    <chr>     ## 1 CL1      P10-15   I         ## 2 CL2      P53.5-56 I         ## 3 TL       P24-29.5 I # replacing PEX with actual release pool cr_data %<>%   mutate(patch_0 = ifelse(str_sub(patch_0, 1, 3) == \"PEX\",                           paste(\"PEX\", streamID, sep = \"-\"),                           as.character(patch_0))) %>%   mutate(patch_0 = str_replace_all(patch_0,                                    c(\"PEX-CL1\" = \"P10-15\",                                      \"PEX-CL2\" = \"P53.5-56\",                                      \"PEX-TL\" = \"P24-29.5\")                                    ))"},{"path":"https://sebastianodebona.github.io/guppyDme/articles/DME-000_Tidy_data.html","id":"growth-dispersal-habitat-shift","dir":"Articles","previous_headings":"","what":"Growth, dispersal, habitat shift","title":"Tidy the data","text":"can now check whether individuals dispersed changed habitat time two captures. can also estimate growth mm, time capture recapture. can calculate time days comparing release time first capture capture time recapture. last necessary step calculate actual percentages increase decrease density treatments. aim manipulation modify density 40 (CL1), 50 (TL) 60% (CL2). actual proportion can calculated capture form. proceeding, explained treatment levels (quite ) mean: C: control treatment. Fish assigned treatment captured released control pool. Density unaltered. : increased treatment. Fish captured pool increased. resident fish, reintroduced increased density pool, together fish (see ). analyses effects density restricted resident fish, experiencing higher density. E: extralimital fish. Fish captured elsewhere (outside manipulated reach), introduced increased treatment. analyses won’t concern fish since ’re movement likely affected displaced, addition density. D: decreased fish. Fish captured pool density decreased, released back pool. resident fish stay, experience lower density. R: removed fish. Fish captured pool density decreased, won’t released back pool. displaced downstream, allowing decrease density. XR: accidentally removed fish. TL two bottles belonging different pools mixed together accident, laboratory. 20+27 fish removed reach. pool marked XR fish considered removed decreased density pool (one mixed pools). fish counted establishing many fish removed TL. X: accidentally removed fish, increased density pool. fish also mixed (see ). remove increased pool. fish counted establishing original density increased pool TL. can now summarise data streamID treatment, transform wide format can reshape table better way facilitate merging. newly added variable density_factor allows use density continous variable analyses.","code":"# an individual is considered dispersed if the patch ID between 0 and 1 (cap and recap) # is different. Since in the prep-data step we have established unique patchIDs between # capture and recapture event, this correponds to an actual movement. cr_data %<>%   mutate(moved = patch_0 != patch_1,          hshift = habitat_0 != habitat_1,          interval = captureDate - releaseDate,          growth = as.numeric(as.character(SL_1)) - as.numeric(as.character(SL_0))          ) # we only need capture data all_capture <- data %>%   filter(recap == 0, streamID != \"TM\") treatment_tab <- all_capture %>%   filter(!is.na(treatment)) %>%   group_by(streamID, treatment) %>%   count %>%   spread(treatment, n) %>%   print ## # A tibble: 3 × 9 ## # Groups:   streamID [3] ##   streamID     C     D     E     I     N     R     X    XR ##   <fct>    <int> <int> <int> <int> <int> <int> <int> <int> ## 1 CL1        193    42    73   163    55    26    NA    NA ## 2 CL2        106    60    31    49    47    89    NA    NA ## 3 TL         100    28    52    63   111     8    27    20 # with operations among columns I can now calculate increase and decrease percentages. treatment_tab %<>%   mutate(Incr_p = round(sum(I, E)/sum(I, X, na.rm = T), 2),          Decr_p = round(D/sum(D, R, XR, na.rm = T), 2)) %>%   print ## # A tibble: 3 × 11 ## # Groups:   streamID [3] ##   streamID     C     D     E     I     N     R     X    XR Incr_p Decr_p ##   <fct>    <int> <int> <int> <int> <int> <int> <int> <int>  <dbl>  <dbl> ## 1 CL1        193    42    73   163    55    26    NA    NA   1.45   0.62 ## 2 CL2        106    60    31    49    47    89    NA    NA   1.63   0.4  ## 3 TL         100    28    52    63   111     8    27    20   1.28   0.5 # see above what is the meaning of the treatment levels here treatment_tab %<>%   select(streamID, Incr_p, Decr_p) %>%   mutate(Contr_p = 1) %>% # the control was always left intact   gather(treatment, density_factor, Incr_p:Contr_p) %>% # wide to long format   mutate(treatment = str_replace_all(treatment, # using same nomenclature as treatment levels                                      c(\"Incr_p\" = \"I\",                                      \"Decr_p\" = \"D\",                                      \"Contr_p\" = \"C\"))) %>%   print ## # A tibble: 9 × 3 ## # Groups:   streamID [3] ##   streamID treatment density_factor ##   <fct>    <chr>              <dbl> ## 1 CL1      I                   1.45 ## 2 CL2      I                   1.63 ## 3 TL       I                   1.28 ## 4 CL1      D                   0.62 ## 5 CL2      D                   0.4  ## 6 TL       D                   0.5  ## 7 CL1      C                   1    ## 8 CL2      C                   1    ## 9 TL       C                   1 #...and merge cr_data <- left_join(cr_data, treatment_tab) ## Joining with `by = join_by(streamID, treatment)` str(cr_data) ## tibble [484 × 24] (S3: tbl_df/tbl/data.frame) ##  $ markID        : Factor w/ 2219 levels \"105K\",\"105Y\",..: 643 781 731 539 581 795 814 461 635 303 ... ##  $ streamID      : Factor w/ 4 levels \"CL1\",\"CL2\",\"TL\",..: 1 1 1 1 1 1 1 1 1 1 ... ##  $ treatment     : chr [1:484] \"I\" \"I\" \"I\" \"I\" ... ##  $ sex_stage_0   : chr [1:484] \"F\" \"F\" \"F\" \"M\" ... ##  $ patch_0       : chr [1:484] \"P10-15\" \"P10-15\" \"P10-15\" \"P10-15\" ... ##  $ habitat_0     : Factor w/ 5 levels \"A\",\"B\",\"C\",\"D\",..: 4 4 4 4 4 4 4 4 2 2 ... ##  $ SL_0          : num [1:484] 21.3 20.6 17.4 17.6 19 ... ##  $ weight_0      : num [1:484] 0.183 0.155 0.071 0.086 0.106 0.061 0.077 0.068 0.13 0.485 ... ##  $ releaseDate   : Date[1:484], format: \"2018-03-21\" \"2018-03-21\" ... ##  $ marker_0      : chr [1:484] \"DKS\" \"DKS\" \"DKS\" \"DKS\" ... ##  $ patch_1       : Factor w/ 33 levels \"B8.5-9\",\"N23-32\",..: 7 7 7 7 7 7 29 10 7 7 ... ##  $ habitat_1     : Factor w/ 5 levels \"A\",\"B\",\"C\",\"D\",..: 1 3 1 3 3 3 NA 3 3 1 ... ##  $ sex_stage_1   : chr [1:484] \"F\" \"F\" \"F\" \"M\" ... ##  $ SL_1          : num [1:484] 22.4 19.3 17.2 17.5 19.7 ... ##  $ weight_1      : num [1:484] 0.158 NA NA 0.099 0.131 NA 0.065 0.102 0.156 NA ... ##  $ captureDate   : Date[1:484], format: \"2018-04-19\" \"2018-04-19\" ... ##  $ marker_1      : chr [1:484] \"DKS\" \"SDB\" \"SDB\" \"DKS\" ... ##  $ pool_treat_0  : chr [1:484] \"increased\" \"increased\" \"increased\" \"increased\" ... ##  $ pool_treat_1  : chr [1:484] \"increased\" \"increased\" \"increased\" \"increased\" ... ##  $ moved         : logi [1:484] FALSE FALSE FALSE FALSE FALSE FALSE ... ##  $ hshift        : logi [1:484] TRUE TRUE TRUE TRUE TRUE TRUE ... ##  $ interval      : 'difftime' num [1:484] 29 29 29 29 ... ##   ..- attr(*, \"units\")= chr \"days\" ##  $ growth        : num [1:484] 1.13 -1.36 -0.14 -0.16 0.67 ... ##  $ density_factor: num [1:484] 1.45 1.45 1.45 1.45 1.45 1.45 1.45 1.45 1.45 1.45 ... # the info on pool-specific treatment is useful to have here too # so we will merge it into this head(treatment_tab <- left_join(pool_to_treat %>% rename(patchID = patch_0), treatment_tab)) ## Joining with `by = join_by(streamID, treatment)` ## # A tibble: 6 × 4 ##   streamID patchID  treatment density_factor ##   <fct>    <fct>    <chr>              <dbl> ## 1 CL1      P10-15   I                   1.45 ## 2 CL1      P16-22   C                   1    ## 3 CL1      P3-10    D                   0.62 ## 4 CL2      P48-53.5 C                   1    ## 5 CL2      P53.5-56 I                   1.63 ## 6 CL2      P59-68.5 D                   0.4"},{"path":"https://sebastianodebona.github.io/guppyDme/articles/DME-000_Tidy_data.html","id":"saving","dir":"Articles","previous_headings":"","what":"Saving","title":"Tidy the data","text":"","code":"# saving the cr dataset saveRDS(cr_data, file = file.path(here::here(), \"vignettes\", \"DME_cr_data.rds\")) # and also the treatment table saveRDS(treatment_tab, file = file.path(here::here(), \"vignettes\", \"DME_density_factor_in_treatments.rds\"))"},{"path":"https://sebastianodebona.github.io/guppyDme/articles/DME-010_Habitat_characteristics.html","id":"overwiew-setup","dir":"Articles","previous_headings":"","what":"Overwiew & Setup","title":"Habitat characteristics","text":"vignette explores microhabitat types defined Density Manipulation Experiment determines different based hydrological ecological measures obtained .","code":"# loading necessary packages # for data handling library(tidyverse) library(magrittr)  # this requires the package guppyDme to be installed. If the user wishes not to install the package, please comment out the \"library(guppyDme)\" line and run instead the lines commented out below  #### If you have the guppyDme package installed # loading package library(guppyDme)  # #### If you do NOT wish to install the guppyDme package, please uncomment and run the following two lines of code, adding the package functions to the Global Environment and loading the data # source(file.path(here::here(), \"R\", \"package_functions.R\")) # load(file.path(here::here(), \"data\", \"DMEhabitat.rda\"))  # loading data habitat <- DMEhabitat"},{"path":"https://sebastianodebona.github.io/guppyDme/articles/DME-010_Habitat_characteristics.html","id":"habitat-exploration","dir":"Articles","previous_headings":"","what":"Habitat exploration","title":"Habitat characteristics","text":"produce plot compare microhabitat types see distninguishable. attaching figure depicts 5 different habitat types, position/appearance pool.     might easier visualize average (range ) values category habitat.","code":"# scoring habitat to obtain numeric values. Using custom function substrate_score habitat %<>%   mutate(substrate_score = score_substrate(substrate))  # toggling with the parameter \"conflicts\"\" in score_substrate() is possible to explore how # only considering finer or coarser substrate type changes results. # Please see the help documentation for the function.  # some of the habitat definitions are still a combination of many habitats (will be sorted later). # for now, I will conly consider the 5 main habitat types when they appear alone  habitat %<>%   filter(habitat %in% c(\"A\", \"B\", \"C\", \"D\", \"E\")) %>%   mutate(habitat = factor(habitat)) # removes empty factor levels  # defining color hues # from https://projects.susielu.com/viz-palette?colors=[%22#ffd700%22,%22#ffb14e%22,%22#fa8775%22,%22#ea5f94%22,%22#cd34b5%22,%22#9d02d7%22,%22#0000ff%22]&backgroundColor=%22white%22&fontColor=%22black%22&mode=%22normal%22 color_hues <- c(   \"#ffd700\",   \"#fa8775\",   \"#cd34b5\",   \"#9d02d7\",   \"#0000ff\")  # Plotting...  # Flow p1 <- ggplot(habitat, aes(x=habitat, y=flow, fill = habitat)) +    geom_violin(scale = \"area\") p1 + ggtitle(\"Flow across habitats\") +   xlab(\"Habitat\") + ylab(\"Water speed (m/s)\") +   geom_boxplot(width=0.05, fill = \"white\") +   scale_x_discrete(labels = hablab()) +   scale_fill_manual(labels = hablab(), values = color_hues) ## Warning: Removed 5 rows containing non-finite outside the scale range ## (`stat_ydensity()`). ## Warning: Removed 5 rows containing non-finite outside the scale range ## (`stat_boxplot()`). # Depth p2 <- ggplot(habitat, aes(x=habitat, y=depth, fill = habitat)) +    geom_violin(scale = \"area\") p2 + ggtitle(\"Depth across habitats\") +   xlab(\"Habitat\") + ylab(\"Water depth (cm)\") +   geom_boxplot(width=0.05, fill = \"white\") +   scale_x_discrete(labels = hablab()) +   scale_fill_manual(labels = hablab(), values = color_hues) ## Warning: Removed 1 row containing non-finite outside the scale range ## (`stat_ydensity()`). ## Warning: Removed 1 row containing non-finite outside the scale range ## (`stat_boxplot()`). # Substrate p3 <- ggplot(habitat, aes(x=habitat, y=substrate_score, fill = habitat)) +    geom_violin(scale = \"area\") p3 + ggtitle(\"Substrate coarseness\") +   xlab(\"Habitat\") + ylab(\"Substrate type\") +   geom_boxplot(width=0.05, fill = \"white\") +   scale_y_continuous(breaks = c(0,1,2,3,4),                       labels = c(\"silt\", \"sand\", \"gravel\", \"pebbles\", \"rock\")) +   scale_x_discrete(labels = hablab()) +   scale_fill_manual(labels = hablab(), values = color_hues) ## Warning: Removed 2 rows containing non-finite outside the scale range ## (`stat_ydensity()`). ## Warning: Removed 2 rows containing non-finite outside the scale range ## (`stat_boxplot()`). # Organic Matter om <- habitat %>%   group_by(habitat) %>%   summarize(detritus = mean(detritus, na.rm = T),             leaves = mean(leaves, na.rm = T)) om %<>%   gather(key = organic_matter, value = p, detritus, leaves)  ggplot(om, aes(x = habitat, y = p, fill = organic_matter)) +    ggtitle(\"Organic matter presence\") +   xlab(\"Habitat\") + ylab(\"Proportion present\") +   geom_bar(stat=\"identity\", position=position_dodge()) +   ylim(0, 1) +   scale_fill_manual(values=c(\"#999999\", \"#339933\")) +   scale_x_discrete(labels = hablab()) habitat %>%   select(streamID, habitat, depth, flow, substrate_score, detritus, leaves) %>%   gather(key = variable, value = value, depth, flow, substrate_score, detritus, leaves) %>%   group_by(habitat, variable) %>%   summarize(mean_value = mean(value, na.rm = T),             lo_q = quantile(value, 0.025, na.rm = T),             hi_q = quantile(value, 0.975, na.rm = T)) %>%   mutate(mean_value = round(mean_value, 2),          lo_q = round(lo_q, 2),          hi_q = round(hi_q, 2)) %>%   add_column(bl = \"[\",              br = \"]\") %>%   unite(range, lo_q, hi_q, sep = \" - \") %>%   unite(range, bl, range, br, sep = \"\") %>%   unite(value, mean_value, range, sep = \" \") %>%   spread(key = variable, value = value) ## `summarise()` has grouped output by 'habitat'. You can override using the ## `.groups` argument. ## # A tibble: 5 × 6 ## # Groups:   habitat [5] ##   habitat depth               detritus     flow           leaves substrate_score ##   <fct>   <chr>               <chr>        <chr>          <chr>  <chr>           ## 1 A       11.84 [1.85 - 37.2] 0.04 [0 - 1] 0.32 [0 - 1]   0.05 … 2.71 [1 - 4]    ## 2 B       4.9 [0.97 - 13.53]  0.44 [0 - 1] 0.03 [0 - 0.2] 0.18 … 1.42 [0.49 - 4] ## 3 C       15.11 [1 - 43.6]    0.55 [0 - 1] 0.09 [0 - 0.4] 0.25 … 2.27 [1 - 4]    ## 4 D       6.37 [0 - 17.3]     0.75 [0 - 1] 0.01 [0 - 0.1] 0.59 … 1.8 [0 - 4]     ## 5 E       10.27 [0.58 - 22]   0.24 [0 - 1] 0.2 [0 - 0.7]  0.12 … 2.63 [1 - 4]"},{"path":"https://sebastianodebona.github.io/guppyDme/articles/DME-015_Habitat_area.html","id":"overview-setup","dir":"Articles","previous_headings":"","what":"Overview & setup","title":"Habitat area","text":"calculate relative area habitat, pool. allow us account habitat availability analyzing habitat use.","code":"# loading packages library(tidyverse) ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ── ## ✔ dplyr     1.1.4     ✔ readr     2.1.5 ## ✔ forcats   1.0.0     ✔ stringr   1.5.1 ## ✔ ggplot2   3.5.1     ✔ tibble    3.2.1 ## ✔ lubridate 1.9.3     ✔ tidyr     1.3.1 ## ✔ purrr     1.0.2      ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag()    masks stats::lag() ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors library(magrittr) ##  ## Attaching package: 'magrittr' ##  ## The following object is masked from 'package:purrr': ##  ##     set_names ##  ## The following object is masked from 'package:tidyr': ##  ##     extract # this vignette requires the package guppyDme to be installed. If the user wishes not to install the package, please comment out the \"library(guppyDme)\" line and run instead the lines commented out below  #### If you have the guppyDme package installed # loading package library(guppyDme)  # # If you do NOT wish to install the guppyDme package, please uncomment and run the following two lines of code, adding the package functions to the Global Environment and loading the data # source(file.path(here::here(), \"R\", \"package_functions.R\")) # load(file.path(here::here(), \"data\", \"DMEhabitat.rda\"))  habitat <- DMEhabitat str(habitat) ## tibble [1,352 × 17] (S3: tbl_df/tbl/data.frame) ##  $ stream            : chr [1:1352] \"CA\" \"CA\" \"CA\" \"CA\" ... ##  $ streamID          : chr [1:1352] \"CL1\" \"CL1\" \"CL1\" \"CL1\" ... ##  $ date              : Date[1:1352], format: \"2018-03-21\" \"2018-03-21\" ... ##  $ reach             : chr [1:1352] \"P16-22\" \"P16-22\" \"P16-22\" \"P16-22\" ... ##  $ cap_recap         : chr [1:1352] \"cap\" \"cap\" \"cap\" \"cap\" ... ##  $ x                 : int [1:1352] -50 0 50 100 150 200 250 300 -50 0 ... ##  $ y                 : num [1:1352] 23 23 23 23 23 23 23 23 22.5 22.5 ... ##  $ depth             : num [1:1352] 0 10.7 9.5 14.8 7.8 6 4.5 1 1 1.5 ... ##  $ habitat           : chr [1:1352] \"E\" \"E\" \"E\" \"E\" ... ##  $ flow              : num [1:1352] NA 0.4 0.6 0.7 0 0.5 0 0 0 0.2 ... ##  $ recorded_substrate: chr [1:1352] \"rocks\" \"rock\" \"rock\" \"rock\" ... ##  $ detritus          : int [1:1352] 0 0 0 0 0 0 1 0 0 0 ... ##  $ leaves            : int [1:1352] 0 0 0 0 0 0 0 1 0 0 ... ##  $ comments          : chr [1:1352] \"\" \"\" \"\" \"\" ... ##  $ substrate         : chr [1:1352] \"pebbles\" \"rock\" \"rock\" \"rock\" ... ##  $ submerged         : num [1:1352] 1 1 1 1 1 1 1 1 1 1 ... ##  $ patchID           : chr [1:1352] \"P16-22\" \"P16-22\" \"P16-22\" \"P16-22\" ... # for future checks NROWS <- nrow(habitat)  # as for the cap-recap data, we will consider # backwaters as habitat D, given the shared properties. habitat %>%   filter(habitat == \"BW\") ## # A tibble: 8 × 17 ##   stream streamID date       reach     cap_recap     x     y depth habitat  flow ##   <chr>  <chr>    <date>     <chr>     <chr>     <int> <dbl> <dbl> <chr>   <dbl> ## 1 TY     TL       2018-03-25 \"B8.5-9 \" cap         100   9.5    40 BW        0.1 ## 2 TY     TL       2018-03-25 \"B8.5-9 \" cap         150   9       7 BW        0   ## 3 CA     CL2      2018-04-29 \"P33-38.… recap      -170  38       8 BW        0   ## 4 CA     CL2      2018-04-29 \"P33-38.… recap      -250  37       2 BW        0   ## 5 CA     CL2      2018-04-29 \"P33-38.… recap      -200  37       3 BW        0   ## 6 CA     CL2      2018-04-29 \"P33-38.… recap      -250  36      16 BW        0   ## 7 CA     CL2      2018-04-29 \"P33-38.… recap      -200  36      15 BW        0   ## 8 CA     CL2      2018-04-29 \"P33-38.… recap      -150  36      10 BW        0   ## # ℹ 7 more variables: recorded_substrate <chr>, detritus <int>, leaves <int>, ## #   comments <chr>, substrate <chr>, submerged <dbl>, patchID <chr> # this only occurs for 2 pools: an actual backwater in TL, # and a backwater in P33-38.5, which sits between CL1 and CL2 habitat %<>%   mutate(habitat = ifelse(habitat == \"BW\", \"D\", habitat))"},{"path":"https://sebastianodebona.github.io/guppyDme/articles/DME-015_Habitat_area.html","id":"visualising-the-streams","dir":"Articles","previous_headings":"Overview & setup","what":"Visualising the streams","title":"Habitat area","text":"area calculated separately stream/capture event/pool combination. Using tidyr can group dataset apply calculations unique combinations. make sure data area generate compatible capture-recapture dataset, use shared patchID variable (generated file reach_key.csv), rather reach. get better idea data, want find way visualise distribution tiles stream. plotting, side side, capture recapture stream.  instances habitat measurments, least case Taylor Low Predation, conducetd differently. recapture measurements main pools, avoids riffle areas (time constraints).  Similar issues Caigual.","code":"# using a nested dataset approach by_pool <- habitat %>%   select(-reach) %>%   group_by(cap_recap, streamID, patchID) %>%   nest()  head(by_pool$data[[1]]) ## # A tibble: 6 × 13 ##   stream date           x     y depth habitat  flow recorded_substrate detritus ##   <chr>  <date>     <int> <dbl> <dbl> <chr>   <dbl> <chr>                 <int> ## 1 CA     2018-03-21   -50    23   0   E        NA   rocks                     0 ## 2 CA     2018-03-21     0    23  10.7 E         0.4 rock                      0 ## 3 CA     2018-03-21    50    23   9.5 E         0.6 rock                      0 ## 4 CA     2018-03-21   100    23  14.8 E         0.7 rock                      0 ## 5 CA     2018-03-21   150    23   7.8 E         0   gravel                    0 ## 6 CA     2018-03-21   200    23   6   E/D       0.5 gravel                    0 ## # ℹ 4 more variables: leaves <int>, comments <chr>, substrate <chr>, ## #   submerged <dbl> # plotting Taylor LP capture and recapture # by mistake, the x values for capture are inverted, so we will transform them here tp <- by_pool %>%   filter(streamID == \"TL\") %>%   select(data, cap_recap) %>%   unnest(data) %>%   mutate(x = ifelse(cap_recap == \"cap\", -x, x)) ## Adding missing grouping variables: `streamID`, `patchID` # We will replace the letter legend with word-explanations of the  habitats hab_names <- sort(unique(tp$habitat))%>%   str_replace_all(hablab()) %>%   str_replace(\"beachW\", \"BW\") %>%   c(\"NA\")  ggplot(tp, aes(x = y, y = -x, color = habitat)) +    geom_point(size = 3, shape = 15) +   ylim(-500, 500) +   geom_point(aes(shape=factor(submerged)), size = 1, color=\"black\") +   scale_shape_manual(values = c(19, 1)) +   scale_color_discrete(labels = hab_names) +   facet_grid(cap_recap ~ ., scales = \"free\") # now plotting Caigual, 1 then 2 c1p <- by_pool %>%   filter(streamID == \"CL1\") %>%   select(data, cap_recap) %>%   unnest(data) ## Adding missing grouping variables: `streamID`, `patchID` # replacing letter legend with word-explanations hab_names_c1p <- sort(unique(c1p$habitat))%>%   str_replace_all(hablab()) %>%   str_replace(\"beachW\", \"BW\") %>%   c(\"NA\")  c2p <- by_pool %>%   filter(streamID == \"CL2\") %>%   select(data, cap_recap) %>%   unnest(data) ## Adding missing grouping variables: `streamID`, `patchID` # replacing letter legend with word-explanations hab_names_c2p <- sort(unique(c2p$habitat))%>%   str_replace_all(hablab()) %>%   str_replace(\"beachW\", \"BW\") %>%   c(\"NA\")  ggplot(c1p, aes(x = y, y = -x, color = habitat)) +    geom_point(size = 3, shape = 15) +   ylim(-500, 500) +   geom_point(aes(shape=factor(submerged)), size = 1, color=\"black\") +   scale_shape_manual(values = c(19, 1)) +   scale_color_discrete(labels = hab_names_c1p) +   facet_grid(cap_recap ~ ., scales = \"free\") ggplot(c2p, aes(x = y, y = -x, color = habitat)) +    geom_point(size = 3, shape = 15) +   ylim(-500, 500) +   geom_point(aes(shape=factor(submerged)), size = 1, color=\"black\") +   scale_shape_manual(values = c(19, 1)) +   scale_color_discrete(labels = hab_names_c2p) +   facet_grid(cap_recap ~ ., scales = \"free\")"},{"path":"https://sebastianodebona.github.io/guppyDme/articles/DME-015_Habitat_area.html","id":"calculating-habitat-areas","dir":"Articles","previous_headings":"Overview & setup","what":"Calculating habitat areas","title":"Habitat area","text":"easiest way calculate relative bethic area different habitats pool count size grid (50cm2 1m2) time habitat recorded pool. shared habitats (e.g. ‘b/c’) tile size can divided many habitats share , fraction allocated habitats involved. streams though measures x y axis happen uneven intervals, seldom exactly 50cm 1m long. better alternative , point grid, calculate distance point ’s right, left, upstream downstream, divide two, add distances two axes (right/2 + left/2 upstream/2 + downstream/2) calculate area rectangle sides. try last approach. can use functions lead() lag() obtain points right left grid point. Using group_by() nest() can subset data chunks share y value combination map() mutate() lets us calculate semi-distance grid point point right left. points edge stream transect, assume habitat extends towards edge amount corresponds smallest semi-distance. using measures reflects smallest half-increment considered measures section. One operation left assign semi-distances grid points one transect. means neighboring points calculate semi-distance . ’ve now obtained values semi-distance left right; - downstream. - downstream distance, since downstream boundaries strict ones, semi-distance upstream-point downstream-point 0. left merging d.d d.u values habitat dataframe. can now calculate benthic area “tile”” around grid point. begin checking absurd values distances.  two instances reach short (~1m) defined one transect. reason d.u d.d set 0. set 50 cm , represent 1m reach. can now move onto calculating areas. need transform measures scale. ’ll divide d.r d.l meters. final step calculate relative area habitat pool. set easy way deal shared gridpoints (e.g. /b/e), create variable counts many habitats gridpoint shared. can now use nested dataset approach calculate relative total area different habitats. visualize composition pool can plot relative area.  pools chunk percentage missing. ’s due presence either boundary common riffle weird habitat (F P59.68.5) yield guppies.","code":"by_y <- habitat %>%   group_by(cap_recap, streamID, patchID, y) %>%   nest() by_y %<>%   # first, arranging each tibble by increasing values of x   mutate(data = map(data, ~.x %>%                       arrange(x))) %>%   # then calculating semi-distances along the x axis   mutate(data = map(data, ~ .x %>%                       mutate(d.r = abs(x - lag(x))/2,                              d.l = abs(x - lead(x))/2,                              # and adding semi-distances to edges                              d.r = ifelse(length(d.r)>1 & is.na(d.r), min(d.r, na.rm = T), d.r),                              d.l = ifelse(length(d.l)>1 & is.na(d.l), min(d.l, na.rm = T), d.l)                     ))) by_reach <- by_y %>%   # unnesting and regrouping by reach only   unnest(cols = c(data)) %>%   group_by(cap_recap, streamID, patchID) %>%   nest()  # adding median value to \"lonely\" grid points habitat <- by_reach %>% mutate(data = map(data, ~ .x %>%                       mutate(d.r = replace(d.r, is.na(d.r), median(d.r, na.rm = T)),                              d.l = replace(d.r, is.na(d.r), median(d.r, na.rm = T))                     ))) %>%   unnest(cols = c(data))  # checking the number of row matches after unnesting stopifnot(nrow(habitat)==NROWS) whys <- by_y %>%   # trimming away the nested tibbles   select(cap_recap, streamID, patchID, y) %>%   # re-grouping and desting   group_by(cap_recap, streamID, patchID) %>%    nest() %>%   # sorting by values of y   mutate(data = map(data, ~.x %>%                       arrange(y))) %>%   # calculating semi-distances on the y axis   mutate(data = map(data, ~.x %>%                       mutate(d.d = ifelse(is.na(lag(y)), 0, abs(lag(y)-y)/2),                              d.u = ifelse(is.na(lead(y)), 0, abs(lead(y)-y)/2)                              ))) %>%   unnest(cols = c(data)) habitat <- left_join(habitat, whys, by = c(\"cap_recap\", \"streamID\", \"patchID\", \"y\")) # check stopifnot(nrow(habitat)==NROWS) par(mfrow = c(2,2)) hist(habitat$d.r, main = \"right\", xlab = \"cm\") hist(habitat$d.l, main = \"left\", xlab = \"cm\") hist(habitat$d.u, main = \"upstream\", xlab = \"m\") hist(habitat$d.d, main = \"downstream\", xlab = \"m\") habitat[which(habitat$d.d==0 & habitat$d.u==0),] ## # A tibble: 6 × 21 ## # Groups:   cap_recap, streamID, patchID [2] ##   streamID cap_recap patchID     y stream date       reach      x depth habitat ##   <chr>    <chr>     <chr>   <dbl> <chr>  <date>     <chr>  <int> <dbl> <chr>   ## 1 TM       cap       P29-30     29 TY     2018-04-09 P29-30   -80     6 R       ## 2 TM       cap       P29-30     29 TY     2018-04-09 P29-30   -50     6 R       ## 3 TM       cap       P29-30     29 TY     2018-04-09 P29-30     0     6 R       ## 4 TM       cap       R19-20     20 TY     2018-04-09 R19-20  -100     6 R       ## 5 TM       cap       R19-20     20 TY     2018-04-09 R19-20   -50    NA NA      ## 6 TM       cap       R19-20     20 TY     2018-04-09 R19-20     0     6 R       ## # ℹ 11 more variables: flow <dbl>, recorded_substrate <chr>, detritus <int>, ## #   leaves <int>, comments <chr>, substrate <chr>, submerged <dbl>, d.r <dbl>, ## #   d.l <dbl>, d.d <dbl>, d.u <dbl> habitat[which(habitat$d.d==0 & habitat$d.u==0), c(\"d.d\", \"d.u\")] <- .5 habitat %<>%   mutate(d.l = d.l/100,          d.r = d.r/100,          ba = (d.l + d.r)*(d.u + d.d)) # creating a variable that defines how many habitats share a grid point habitat %<>%   mutate(parts = str_count(habitat, \"/\") + 1) # creating a custom function to pick out habitats and sum bentic area  add_habitat <- function(data, pattern){   if(pattern == \"all\"){     data %>%        pull(ba) %>%       sum(na.rm = T)   } else {     data %>%     filter(str_detect(habitat, pattern)) %>%     mutate(ba_parted = ba/parts) %>%     pull(ba_parted) %>%     sum(na.rm = T)   } }  # applying the function to all habitats of interest. In the process removing # no habitats (banks and emerged) by_pool <- habitat %>%   filter(!is.na(habitat)) %>%   group_by(cap_recap, streamID, patchID) %>%   nest() %>%   mutate(A = map(data, add_habitat, \"A\"),          B = map(data, add_habitat, \"B\"),          C = map(data, add_habitat, \"C\"),          D = map(data, add_habitat, \"D\"),          E = map(data, add_habitat, \"E\"),          tot = map(data, add_habitat, \"all\"))  # unnesting pool_comp <- by_pool %>%   select(-data) %>%   unnest(cols = c(A, B, C, D, E, tot))  # calculating relative areas pool_comp %<>%   mutate(relA = A/tot,          relB = B/tot,          relC = C/tot,          relD = D/tot,          relE = E/tot) # finding which pools are present before and after shared_pools <- intersect(pool_comp %>% filter(cap_recap == \"cap\") %>% pull(patchID),                            pool_comp %>% filter(cap_recap == \"recap\") %>% pull(patchID))  # first, reshaping the dataframe toplot <- pool_comp %>%   filter(streamID != \"TM\", str_sub(patchID, 1, 1)==\"P\") %>%   select(-c(A, B, C, D, E, tot)) %>%   rename(A=relA, B=relB, C=relC, D=relD, E=relE)  %>%   gather(A, B, C, D, E, key = habitat, value = ba)  # # Displaying all pools (no riffles) # ggplot(toplot, aes(x = patchID, y = ba, fill = habitat)) +  #   geom_bar(stat = \"identity\") + #   facet_grid(cap_recap ~., scales = \"free\") + #   scale_fill_discrete(labels = hablab()) + #   theme(axis.text.x = element_text(angle = 45, hjust = 1)) + #   ggtitle(\"All pools\")  # We can now display only the shared pools between capture and recapture ggplot(toplot %>% filter(patchID %in% shared_pools),        aes(x = patchID, y = ba, fill = habitat)) +    geom_bar(stat = \"identity\") +   facet_grid(cap_recap ~., scales = \"free\") +   scale_fill_discrete(labels = hablab()) +   theme(axis.text.x = element_text(angle = 45, hjust = 1)) +   ggtitle(\"Shared pools only\")"},{"path":"https://sebastianodebona.github.io/guppyDme/articles/DME-015_Habitat_area.html","id":"saving-output","dir":"Articles","previous_headings":"Overview & setup","what":"Saving output","title":"Habitat area","text":"","code":"saveRDS(pool_comp, file = file.path(here::here(), \"vignettes\", \"DME_pool_composition.rds\"))"},{"path":"https://sebastianodebona.github.io/guppyDme/articles/DME-016_Dispersal_and_habitat_shift.html","id":"overview-setup","dir":"Articles","previous_headings":"","what":"Overview & Setup","title":"Dispersal and Habitat shift","text":"analyse effects density dispersal. hypothesis higher density force individuals disperse, given stronger competition resources. vignette relies previous vignettes (000, 010, 015) run, since builds upon capture-recapture dataset generated.","code":"library(tidyverse) library(ggpubr) library(lme4) library(stargazer) library(magrittr)  # this vignette requires the package guppyDme to be installed. If the user wishes not to install the package, please comment out the \"library(guppyDme)\" line and run instead the lines commented out below  #### If you have the guppyDme package installed # loading package library(guppyDme)  # # If you do NOT wish to install the guppyDme package, please uncomment and run the following two lines of code, adding the package functions to the Global Environment and loading the data # source(file.path(here::here(), \"R\", \"package_functions.R\"))  # here we load the capture-recapture dataset. cr_data <- readRDS(file.path(here::here(), \"vignettes\", \"DME_cr_data.rds\"))"},{"path":"https://sebastianodebona.github.io/guppyDme/articles/DME-016_Dispersal_and_habitat_shift.html","id":"dispersal","dir":"Articles","previous_headings":"","what":"Dispersal","title":"Dispersal and Habitat shift","text":"Let’s look fluxes dispersal different treatments.  graphic representation includes individuals extra-limital reaches introduced increased-density pool. Let’s look “resident” individuals . Also, ’ll pooling together “control” “natural” areas since density equilibrium .  test effect density dispersal ’ll run GLMM binomial error distribution. include interval (time) offset, binomial models needs log scale (see: ). model non-logged offset throws error, interval covariate now. First, run model including density continuous factor, together initial standard length sex-stage. Model selection (continous density) Since might asymmetry way density affects dispersal, also try fit model treatment categorical variable, structure covariates. Model selection (factorial density) two resulting models, model simplification approach, whether treatment (density) included continuous categorical variable, need compare AIC values.  can dive little deeper dispersal probability changes based size sex density. plot shows predicted dispersal probability function standard length (mm), marginalized random effect stream_ID, females, males, immature individuals separately. predictions bound appropriate parameter space, spanning minimum maximum recorded size three sex-stage categories.","code":"# here all individuals mat <- cr_data %>%   filter(moved) %>%   select(pool_treat_1, pool_treat_0) %>%   table() %T>%   print %>%   as.data.frame() ##             pool_treat_0 ## pool_treat_1 control decreased increased natural ##    control         1         1        19       7 ##    decreased       7         0        17      14 ##    increased      14         8         1       3 ##    natural        10         4        22      15 ggplot(mat, aes(x = pool_treat_0, y = pool_treat_1, fill = Freq)) +   geom_tile() +    scale_fill_distiller(palette = \"YlOrRd\", direction = 2) +   ylab(\"destination\") + xlab(\"origin\") +   geom_text(aes(label=Freq), size = 8) +    ggtitle(\"All individuals\") mat1 <- cr_data %>%   filter(moved, treatment %in% c(\"C\", \"I\", \"D\")) %>%   mutate(pool_treat_1 = ifelse(pool_treat_1==\"natural\", \"control\", pool_treat_1)) %>%   select(pool_treat_1, pool_treat_0) %>%   table() %>%   as.data.frame() ggplot(mat1, aes(x = pool_treat_0, y = pool_treat_1, fill = Freq)) +   geom_tile() +    scale_fill_distiller(palette = \"YlOrRd\", direction = 2) +   ylab(\"destination\") + xlab(\"origin\") +   geom_text(aes(label=Freq), size = 8) +   ggtitle(\"Extralimital excluded\") # it might be best to rescale the variables to improve model convergence # I am also only selecting resident individuals (excluding extralimital # in increased density pools) cr_data %<>%   filter(treatment %in% c(\"C\", \"D\", \"I\")) %>%   mutate(SL_0s = scale(SL_0),          interval = scale(as.numeric(interval)),          density_factor = density_factor - 1)  d0 <- glmer(moved ~ SL_0s*sex_stage_0*density_factor + (1|streamID),             family = \"binomial\",             offset = interval,             control = glmerControl(optimizer = \"bobyqa\",                                     optCtrl = list(maxfun = 100000)),             na.action = na.omit,             data = cr_data) # remove the three way (not significant at the .10 level) d1 <- glmer(moved ~ (SL_0s+sex_stage_0+density_factor)^2 + (1|streamID),             family = \"binomial\",             offset = interval,             control = glmerControl(optimizer = \"bobyqa\",                                     optCtrl = list(maxfun = 100000)),             na.action = na.omit,             data = cr_data) # remove size x density d2 <- glmer(moved ~ SL_0s*sex_stage_0+sex_stage_0*density_factor + (1|streamID),             family = \"binomial\",             offset = interval,             control = glmerControl(optimizer = \"bobyqa\",                                     optCtrl = list(maxfun = 100000)),             na.action = na.omit,             data = cr_data) # remove sex x density d3 <- glmer(moved ~ SL_0s*sex_stage_0+density_factor + (1|streamID),             family = \"binomial\",             offset = interval,             control = glmerControl(optimizer = \"bobyqa\",                                     optCtrl = list(maxfun = 100000)),             na.action = na.omit,             data = cr_data) # remove density d4 <- glmer(moved ~ SL_0s*sex_stage_0 + (1|streamID),             family = \"binomial\",             offset = interval,             control = glmerControl(optimizer = \"bobyqa\",                                     optCtrl = list(maxfun = 100000)),             na.action = na.omit,             data = cr_data) stargazer::stargazer(d0, d1, d2, d3, d4,                      type = \"html\", report = ('vcp*'),                      title  = \"Model selection (continous density)\",                      dep.var.labels = 'Probability to disperse',                      column.sep.width = \"10pt\",                      omit.stat = c(\"bic\"),                      star.char = c('.', '*', '**')) d1b <- glmer(moved ~ SL_0s*sex_stage_0*treatment + (1|streamID),             family = \"binomial\",             offset = interval,             na.action = na.omit,             data = cr_data) ## Warning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, : ## unable to evaluate scaled gradient ## Warning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, : ## Model failed to converge: degenerate Hessian with 1 negative eigenvalues # the model throws some convergence warnings d2b <- glmer(moved ~ (SL_0s+sex_stage_0+treatment)^2 + (1|streamID),             family = \"binomial\",             offset = interval,             na.action = na.omit,             data = cr_data) ## Warning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, : Model is nearly unidentifiable: large eigenvalue ratio ##  - Rescale variables? d3b <- glmer(moved ~ SL_0s*sex_stage_0+SL_0s*treatment  + (1|streamID),             family = \"binomial\",             offset = interval,             na.action = na.omit,             data = cr_data) d4b <- glmer(moved ~ SL_0s*sex_stage_0+treatment  + (1|streamID),             family = \"binomial\",             offset = interval,             na.action = na.omit,             data = cr_data) d5b <- glmer(moved ~ SL_0s*sex_stage_0 + (1|streamID),             family = \"binomial\",             offset = interval,             na.action = na.omit,             data = cr_data) # displaying model comparison (the first two models don't converge and are not reported) stargazer::stargazer(d3b, d4b, d5b,                      type = \"html\", report = ('vcp*'),                      title  = \"Model selection (factorial density)\",                      dep.var.labels = 'Probability to disperse',                      column.sep.width = \"10pt\",                      omit.stat = c(\"bic\"),                      star.char = c('.', '*', '**')) summary(d4) ## Generalized linear mixed model fit by maximum likelihood (Laplace ##   Approximation) [glmerMod] ##  Family: binomial  ( logit ) ## Formula: moved ~ SL_0s * sex_stage_0 + (1 | streamID) ##    Data: cr_data ##  Offset: interval ## Control: glmerControl(optimizer = \"bobyqa\", optCtrl = list(maxfun = 1e+05)) ##  ##      AIC      BIC   logLik deviance df.resid  ##    352.1    379.3   -169.0    338.1      355  ##  ## Scaled residuals:  ##     Min      1Q  Median      3Q     Max  ## -1.3415 -0.4856 -0.4066 -0.2703  8.7115  ##  ## Random effects: ##  Groups   Name        Variance Std.Dev. ##  streamID (Intercept) 1.774    1.332    ## Number of obs: 362, groups:  streamID, 3 ##  ## Fixed effects: ##                    Estimate Std. Error z value Pr(>|z|)     ## (Intercept)         -1.4933     0.8058  -1.853 0.063850 .   ## SL_0s               -0.5669     0.2680  -2.115 0.034399 *   ## sex_stage_0I         0.7483     0.5307   1.410 0.158512     ## sex_stage_0M         2.0550     0.5826   3.528 0.000419 *** ## SL_0s:sex_stage_0I   1.4186     0.5632   2.519 0.011768 *   ## SL_0s:sex_stage_0M   1.9429     1.5247   1.274 0.202551     ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## Correlation of Fixed Effects: ##             (Intr) SL_0s  sx__0I sx__0M SL_0:__0I ## SL_0s       -0.139                                ## sex_stag_0I -0.133  0.209                         ## sex_stag_0M -0.123  0.183  0.178                  ## SL_0s:s__0I  0.061 -0.471  0.590 -0.067           ## SL_0s:s__0M  0.012 -0.160 -0.024  0.648  0.089 # quick plot to have a visual idea mean_dispersal <- cr_data %>%   group_by(streamID, treatment, density_factor) %>%   summarize(p_mov = mean(moved, na.rm = T),             st_dev = sd(moved, na.rm = T),             n = n()) %>%    mutate(se = st_dev/sqrt(n)) ## `summarise()` has grouped output by 'streamID', 'treatment'. You can override ## using the `.groups` argument. # then against the continuous density ggplot(mean_dispersal, aes(x = density_factor, y = p_mov, col = streamID)) +    geom_point(size = 4, position = position_dodge(0.1)) +   geom_errorbar(aes(ymin=p_mov - se*2, ymax=p_mov + se*2),                 position = position_dodge(0.1), width=0) +    ylim(0, 1) +    labs(x = \"density multiplier\", y = \"Dispersal probability\", color = \"Stream\") +   scale_color_manual(values=c(\"#DAA323\", \"#691E92\", \"#199958\")) +   ggtitle(\"Dispersal probability as a function of density\") +   theme_bw() # generating newdata to predict probability to disperse sls <- modelr::seq_range(cr_data$SL_0, n = 50) sxs <- unique(cr_data$sex_stage_0)  newdata <- expand.grid(SL_0 = sls,                        sex_stage_0 = sxs) newdata_disp <- newdata %>%   mutate(SL_0s = (SL_0 - attr(cr_data$SL_0s, \"scaled:center\"))/            attr(cr_data$SL_0s, \"scaled:scale\")) %>%   add_column(pred_mov = plogis(predict(d4, newdata = ., re.form = ~0))) %>%   mutate(sex_stage = factor(sex_stage_0, levels = c(\"I\", \"M\", \"F\"))) %>%   filter((sex_stage == \"M\" &             in_range(SL_0, cr_data %>% filter(sex_stage_0 == \"M\") %>% pull (SL_0))) |            (sex_stage == \"I\" &             in_range(SL_0, cr_data %>% filter(sex_stage_0 == \"I\") %>% pull (SL_0))) |            (sex_stage == \"F\" &                in_range(SL_0, cr_data %>% filter(sex_stage_0 == \"F\") %>% pull (SL_0)))) %>%   mutate(sex = plyr::mapvalues(sex_stage,                                c(\"I\", \"M\", \"F\"),                                c(\"immature\", \"males\", \"females\")))    # creating new variable to uniform color cr_data %<>%   mutate(sex_lett =plyr::mapvalues(sex_stage_0,                                    c(\"I\", \"M\", \"F\"),                                    c(\"immature\", \"males\", \"females\")))  # extracting model matrix from selected model and newdata # sourced here(https://stackoverflow.com/questions/53255211/plotting-random-effects-for-a-binomial-glmer-in-ggplot) Xmat <- model.matrix(~SL_0s * sex_stage_0, newdata_disp) # extracting fixed effect vector fixest <- fixef(d4) # calculating predicted values fit <- as.vector(fixest %*% t(Xmat)) # calculating the standard error each estimates SE <- sqrt(diag(Xmat %*% vcov(d4) %*% t(Xmat))) # binomial link function linkinv <- binomial()$linkinv  # adding CI to newdata newdata_disp %<>%    add_column(fitted = linkinv(fit),              lower = linkinv(fit - SE),              upper = linkinv(fit + SE))     pd <- ggplot(newdata_disp, aes(x = SL_0, y = fitted, colour = sex)) +   geom_line() +    geom_ribbon(aes(ymin = lower, ymax = upper, fill = sex),                color = \"transparent\", alpha = 0.5) +   geom_point(data = cr_data, aes(x = SL_0, y = as.numeric(moved),                   colour = factor(sex_lett, levels = c(\"immature\", \"males\", \"females\"))), alpha = 0.5,              position = position_jitter(w = 0, h = 0.05)) +   scale_colour_manual(values = c(\"#1E88E5\", \"#FFC107\", \"#004D40\")) +   scale_fill_manual(values = c(\"#1E88E5\", \"#FFC107\", \"#004D40\")) +   xlab(\"Standard length (mm)\") +   ylab(\"Dispersal probability\") +   theme_bw()  pd # saving figure dir.create(file.path(here::here(), \"vignettes\", \"figures\")) ## Warning in dir.create(file.path(here::here(), \"vignettes\", \"figures\")): ## '/home/runner/work/guppyDme/guppyDme/vignettes/figures' already exists jpeg(file.path(here::here(), \"vignettes\", \"figures\", \"dispersal_p_by_sex.jpeg\"),      width = 7, height = 5, units = \"in\", res = 400) pd dev.off() ## agg_png  ##       2"},{"path":"https://sebastianodebona.github.io/guppyDme/articles/DME-016_Dispersal_and_habitat_shift.html","id":"habitat-shift","dir":"Articles","previous_headings":"","what":"Habitat shift","title":"Dispersal and Habitat shift","text":", let’s first visualize type habitat change observe three different pools, among individuals stayed left pool.  lot individuals stayed pool (disperse) moved core pool. repeat analyses dispersal, now habitat shift. addition, including quadratic term since expect increase decrease density result habitat change (either worse better habitats, respectively). ’ll analyse individuals disperse, individuals disperse changed pool well microhabitat, choice shift microhabitat might therefore confounded. Given small sample size, ’s impossible analyse full model includes treatment factor (model rank deficient). account asymmetries response density instead include quadratic term. Model selection probability change habitat increases high density average sized individuals, opposite true large individuals. can explained large individuals monopolizing resources either inaccessible smaller individuals (e.g. drift feeding), holding preferentially even density high (context-competition like dynamic). , visualize results plot.  Given impossible fit full model treatment factorial variable (model rank deficient), briefly refit selected model treatment factor instead continuous variable, compare results.","code":"mat <- cr_data %>%   filter(treatment %in% c(\"C\", \"D\", \"I\")) %>%   select(habitat_0, habitat_1, treatment, moved) %>%   table() %T>%   print %>%   as.data.frame() ## , , treatment = C, moved = FALSE ##  ##          habitat_1 ## habitat_0  A  B  C  D  E ##         A 10  0 16  0  3 ##         B  9  0 10  0  0 ##         C  8  0 59  0  4 ##         D  3  0  7  0  6 ##         E  5  0  6  0  9 ##  ## , , treatment = D, moved = FALSE ##  ##          habitat_1 ## habitat_0  A  B  C  D  E ##         A  4  0  6  0  0 ##         B  1  0  5  0  0 ##         C  7  0 18  0  0 ##         D  0  0  1  0  0 ##         E  0  0  0  0  0 ##  ## , , treatment = I, moved = FALSE ##  ##          habitat_1 ## habitat_0  A  B  C  D  E ##         A  6  0 14  0  0 ##         B  8  0 22  0  0 ##         C  5  0 18  0  0 ##         D  4  0 11  0  0 ##         E  0  0  0  0  0 ##  ## , , treatment = C, moved = TRUE ##  ##          habitat_1 ## habitat_0  A  B  C  D  E ##         A  1  0  2  0  0 ##         B  1  0  1  0  1 ##         C  2  0 15  0  0 ##         D  0  0  1  0  0 ##         E  0  0  4  0  0 ##  ## , , treatment = D, moved = TRUE ##  ##          habitat_1 ## habitat_0  A  B  C  D  E ##         A  1  0  2  0  0 ##         B  0  0  1  1  0 ##         C  3  0  4  0  0 ##         D  0  0  0  0  0 ##         E  0  0  0  0  0 ##  ## , , treatment = I, moved = TRUE ##  ##          habitat_1 ## habitat_0  A  B  C  D  E ##         A  1  0  2  0  0 ##         B  1  0  3  0  2 ##         C  3  0  4  1  0 ##         D  1  0  5  0  1 ##         E  0  0  0  0  0 pool_lables = c(\"C\" = \"control\",                 \"D\" = \"decreased\",                 \"I\" = \"increased\") moved_labels = c(\"FALSE\" = \"STAYED\",                  \"TRUE\" = \"DISPERSED\")  ggplot(mat, aes(x = habitat_0, y = habitat_1, fill = Freq)) +   geom_tile() +    scale_fill_distiller(palette = \"YlOrRd\", direction = 2) +   ylab(\"destination\") + xlab(\"origin\") +   geom_text(aes(label=Freq), size = 8) +   facet_grid(moved ~ treatment, labeller = labeller(treatment = pool_lables, moved = moved_labels)) # Here, individuals who stayed are filtered h1 <- glmer(hshift ~ SL_0s*sex_stage_0*density_factor + I(density_factor^2) + (1|streamID),             offset = interval,             data = cr_data %>% filter(!moved),             control = glmerControl(optimizer = c(\"bobyqa\"),                                     optCtrl = list(maxfun = 100000)),             family  = \"binomial\") # 3-way removed h2 <- glmer(hshift ~ (SL_0s+sex_stage_0+density_factor)^2 + I(density_factor^2) + (1|streamID),             offset = interval,             data = cr_data %>% filter(!moved),             control = glmerControl(optimizer = c(\"bobyqa\"),                                     optCtrl = list(maxfun = 100000)),             family  = \"binomial\") # sex x density removed  h3 <- glmer(hshift ~ SL_0s*sex_stage_0 + SL_0s*density_factor + I(density_factor^2) + (1|streamID),             offset = interval,             data = cr_data %>% filter(!moved),             control = glmerControl(optimizer = c(\"bobyqa\"),                                     optCtrl = list(maxfun = 100000)),             family  = \"binomial\") # size x sex removed h4 <- glmer(hshift ~  SL_0s + sex_stage_0 + SL_0s*density_factor + I(density_factor^2) + (1|streamID),             offset = interval,             data = cr_data %>% filter(!moved),             control = glmerControl(optimizer = c(\"bobyqa\")),             family  = \"binomial\") # quadratic density term removed h5 <- glmer(hshift ~  SL_0s + sex_stage_0 + SL_0s*density_factor + (1|streamID),             offset = interval,             data = cr_data %>% filter(!moved),             control = glmerControl(optimizer = c(\"bobyqa\")),             family  = \"binomial\") # sex removed h6 <- glmer(hshift ~  SL_0s*density_factor + (1|streamID),             offset = interval,             data = cr_data %>% filter(!moved),             control = glmerControl(optimizer = c(\"bobyqa\")),             family  = \"binomial\") # simplified model summary(h6) ## Generalized linear mixed model fit by maximum likelihood (Laplace ##   Approximation) [glmerMod] ##  Family: binomial  ( logit ) ## Formula: hshift ~ SL_0s * density_factor + (1 | streamID) ##    Data: cr_data %>% filter(!moved) ##  Offset: interval ## Control: glmerControl(optimizer = c(\"bobyqa\")) ##  ##      AIC      BIC   logLik deviance df.resid  ##    364.1    382.4   -177.1    354.1      280  ##  ## Scaled residuals:  ##     Min      1Q  Median      3Q     Max  ## -3.9465 -0.7611  0.4396  0.7465  2.7290  ##  ## Random effects: ##  Groups   Name        Variance Std.Dev. ##  streamID (Intercept) 3.25     1.803    ## Number of obs: 285, groups:  streamID, 3 ##  ## Fixed effects: ##                      Estimate Std. Error z value Pr(>|z|)     ## (Intercept)            0.2111     1.0499   0.201  0.84062     ## SL_0s                 -0.1534     0.1255  -1.223  0.22151     ## density_factor         2.1329     0.5036   4.235 2.28e-05 *** ## SL_0s:density_factor  -1.1568     0.4014  -2.882  0.00395 **  ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## Correlation of Fixed Effects: ##             (Intr) SL_0s  dnsty_ ## SL_0s       -0.015               ## densty_fctr -0.002 -0.056        ## SL_0s:dnst_  0.005  0.085 -0.308 # displaying model comparison stargazer::stargazer(h1, h2, h3, h4, h5, h6,                      type = \"html\", report = ('vcp*'),                      title  = \"Model selection\",                      dep.var.labels = '',                      column.sep.width = \"1pt\",                      font.size = \"tiny\",                      omit.stat = c(\"bic\"),                      star.char = c('.', '*', '**')) # defining some representative points for density manipulation (50%, 100%, 150%) ds <- c(-0.5, 0, 0.5)  # calculating predictions from selected model newdata_hab <- expand.grid(SL_0 = sls,                           density_factor = ds) %>%   mutate(SL_0s = (SL_0 - attr(cr_data$SL_0s, \"scaled:center\"))/            attr(cr_data$SL_0s, \"scaled:scale\")) %>%   #add_column(pred_mov = plogis(predict(h6, newdata = ., re.form = ~0))) %>%   mutate(treatment = plyr::mapvalues(density_factor,                                          c(-0.5, 0 , 0.5),                                          c(\"decreased\", \"control\", \"increased\")),          treatment = factor(treatment, levels = c(\"decreased\", \"control\", \"increased\")))  # extracting model matrix from selected model and newdata # sourced here(https://stackoverflow.com/questions/53255211/plotting-random-effects-for-a-binomial-glmer-in-ggplot) Xmat <- model.matrix(~SL_0s * density_factor, newdata_hab) # extracting fixed effect vector fixest <- fixef(h6) # calculating predicted values fit <- as.vector(fixest %*% t(Xmat)) # calculating the standard error each estimates SE <- sqrt(diag(Xmat %*% vcov(h6) %*% t(Xmat))) # binomial link function linkinv <- binomial()$linkinv  # adding CI to newdata newdata_hab %<>%    add_column(fitted = linkinv(fit),              lower = linkinv(fit - SE),              upper = linkinv(fit + SE))    # creating column on cr_data to match newdata alt_data <- cr_data %>%   mutate(treatment = plyr::mapvalues(treatment,                                           c(\"C\", \"D\", \"I\"),                                           c(\"control\", \"decreased\", \"increased\")),          # CAREFUL! The order here is very important and needs to match the order of treatment_lett above          treatment = factor(treatment, levels(newdata_hab$treatment)))   ph <- ggplot(newdata_hab, aes(x = SL_0,                                y = fitted,                                group = treatment)) +   geom_line(aes(colour = treatment),             linewidth = 0.75) +   geom_ribbon(aes(ymin=lower, ymax=upper, fill=treatment), color=NA, alpha=0.3) +   ylim(0, 1) +   geom_point(data = alt_data, aes(x = SL_0,                                    y = as.numeric(hshift),                                    fill = treatment,                                    shape = treatment),              colour = \"black\",               alpha = 0.75,              position = position_jitter(w = 0, h = 0.08)) +   scale_fill_manual(values = c(\"#ffb14e\", \"#cd34b5\", \"#0000ff\")) +   scale_color_manual(values = c(\"#ffb14e\", \"#cd34b5\", \"#0000ff\")) +   scale_shape_manual(values = c(25, 22, 24)) +   xlab(\"Standard length (mm)\") + ylab(\"Predicted microhabitat change (p)\") +   theme_bw() ph ## Warning: Removed 186 rows containing missing values or values outside the scale range ## (`geom_point()`). # saving plot jpeg(file.path(here::here(), \"vignettes\", \"figures\", \"microhabitat_shift_by_treatment.jpeg\"),      width = 7, height = 5, units = \"in\", res = 400) ph ## Warning: Removed 201 rows containing missing values or values outside the scale range ## (`geom_point()`). dev.off() ## agg_png  ##       2 # refitting model with categorical variable h6b <- glmer(hshift ~  SL_0s*treatment + (1|streamID),             offset = interval,             data = cr_data %>% filter(!moved),             control = glmerControl(optimizer = c(\"bobyqa\")),             family  = \"binomial\") summary(h6b) ## Generalized linear mixed model fit by maximum likelihood (Laplace ##   Approximation) [glmerMod] ##  Family: binomial  ( logit ) ## Formula: hshift ~ SL_0s * treatment + (1 | streamID) ##    Data: cr_data %>% filter(!moved) ##  Offset: interval ## Control: glmerControl(optimizer = c(\"bobyqa\")) ##  ##      AIC      BIC   logLik deviance df.resid  ##    366.4    391.9   -176.2    352.4      278  ##  ## Scaled residuals:  ##     Min      1Q  Median      3Q     Max  ## -2.6575 -0.8960  0.4612  0.7318  2.2896  ##  ## Random effects: ##  Groups   Name        Variance Std.Dev. ##  streamID (Intercept) 3.223    1.795    ## Number of obs: 285, groups:  streamID, 3 ##  ## Fixed effects: ##                  Estimate Std. Error z value Pr(>|z|)     ## (Intercept)      -0.03561    1.05199  -0.034  0.97300     ## SL_0s            -0.37498    0.17305  -2.167  0.03024 *   ## treatmentD       -0.39961    0.39282  -1.017  0.30901     ## treatmentI        1.19129    0.31423   3.791  0.00015 *** ## SL_0s:treatmentD  0.94136    0.32593   2.888  0.00387 **  ## SL_0s:treatmentI  0.11873    0.32613   0.364  0.71582     ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## Correlation of Fixed Effects: ##             (Intr) SL_0s  trtmnD trtmnI SL_0:D ## SL_0s        0.005                             ## treatmentD  -0.079 -0.014                      ## treatmentI  -0.091 -0.033  0.211               ## SL_0s:trtmD -0.006 -0.514 -0.130  0.035        ## SL_0s:trtmI  0.002 -0.548  0.000 -0.099  0.268 AIC(h6, h6b) ##     df      AIC ## h6   5 364.1382 ## h6b  7 366.3683 # plotting tts <- c(\"C\", \"D\", \"I\")  newdata_habb <- expand.grid(SL_0 = sls,                           treatment = tts) %>%   mutate(SL_0s = (SL_0 - attr(cr_data$SL_0s, \"scaled:center\"))/            attr(cr_data$SL_0s, \"scaled:scale\")) %>%   add_column(pred_mov = plogis(predict(h6b, newdata = ., re.form = ~0))) %>%    mutate(treatment = plyr::mapvalues(treatment,                                          c(\"D\", \"C\", \"I\"),                                          c(\"decreased\", \"control\", \"increased\")),          treatment = factor(treatment, levels = c(\"decreased\", \"control\", \"increased\")))  ggplot(newdata_habb, aes(x = SL_0,                          y = pred_mov,                          colour = treatment)) +   geom_line(aes(colour = treatment),             linewidth = 1) +   ylim(0, 1) +   geom_point(data = alt_data, aes(x = SL_0,                                    y = as.numeric(hshift),                                    fill = treatment,                                    shape = treatment),              colour = \"black\",               alpha = 0.75,              position = position_jitter(w = 0, h = 0.08)) +   scale_fill_manual(values = c(\"#ffb14e\", \"#cd34b5\", \"#0000ff\")) +   scale_color_manual(values = c(\"#ffb14e\", \"#cd34b5\", \"#0000ff\")) +   scale_shape_manual(values = c(25, 22, 24)) +   xlab(\"standard length (mm)\") +    ylab(\"predicted microhabitat change\") +   theme_bw() ## Warning: Removed 184 rows containing missing values or values outside the scale range ## (`geom_point()`)."},{"path":"https://sebastianodebona.github.io/guppyDme/articles/DME-020_Density_dependence.html","id":"overview-setup","dir":"Articles","previous_headings":"","what":"Overview & Setup","title":"Density dependence","text":"vignette evaluates effects density manipulation fitness proxies recruitment pool, growth, condition. Density dependence lower () life-history traits density increased, viceversa ’s decreased. make interpretation following analyses easier, center variable density_factor (representing much, proportionally, density modified) 1. way, intercepts refer happened control treatment. also filter pools part experiment, therefore interested . Since multiple authors took measurements standard length, account bias measurement include random factor models growth sequence individuals measured fish capture recapture instance.","code":"library(tidyverse) ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ── ## ✔ dplyr     1.1.4     ✔ readr     2.1.5 ## ✔ forcats   1.0.0     ✔ stringr   1.5.1 ## ✔ ggplot2   3.5.1     ✔ tibble    3.2.1 ## ✔ lubridate 1.9.3     ✔ tidyr     1.3.1 ## ✔ purrr     1.0.2      ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag()    masks stats::lag() ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors library(magrittr) ##  ## Attaching package: 'magrittr' ##  ## The following object is masked from 'package:purrr': ##  ##     set_names ##  ## The following object is masked from 'package:tidyr': ##  ##     extract library(car) ## Loading required package: carData ##  ## Attaching package: 'car' ##  ## The following object is masked from 'package:dplyr': ##  ##     recode ##  ## The following object is masked from 'package:purrr': ##  ##     some library(lme4) ## Loading required package: Matrix ##  ## Attaching package: 'Matrix' ##  ## The following objects are masked from 'package:tidyr': ##  ##     expand, pack, unpack library(lmerTest) ##  ## Attaching package: 'lmerTest' ##  ## The following object is masked from 'package:lme4': ##  ##     lmer ##  ## The following object is masked from 'package:stats': ##  ##     step library(ggpubr)  # this vignette requires the package guppyDme to be installed. If the user wishes not to install the package, please comment out the \"library(guppyDme)\" line and run instead the lines commented out below  #### If you have the guppyDme package installed # loading package library(guppyDme)  # #### If you do NOT wish to install the guppyDme package, please uncomment and run the following two lines of code, adding the package functions to the Global Environment and loading the data # source(file.path(here::here(), \"R\", \"package_functions.R\")) # load(file.path(here::here(), \"data\", \"DMEdata.rda\"))  # loading the necessary data data <- DMEdata %>%   mutate(sex_stage = score_sexst(., f_threshold = 14, f_unit = \"SL\"),          sex_stage = factor(sex_stage, levels = c(\"I\", \"M\", \"F\"))) cr_table <- readRDS(file.path(here::here(), \"vignettes\", \"DME_cr_data.rds\")) treatment_tab <- readRDS(file.path(here::here(), \"vignettes\",                                    \"DME_density_factor_in_treatments.rds\")) cr_table %<>%   filter(treatment %in% c(\"C\", \"D\", \"I\")) %>%   mutate(density_factor = density_factor - 1,          marker_seq = str_c(marker_0, marker_1, sep = \"-\"),          treatment = factor(treatment, levels = c(\"C\", \"D\", \"I\")))"},{"path":[]},{"path":"https://sebastianodebona.github.io/guppyDme/articles/DME-020_Density_dependence.html","id":"growth-dispersal","dir":"Articles","previous_headings":"Growth","what":"Growth & Dispersal","title":"Density dependence","text":"growth, consider effect density manipulation change standard length (SL) Linear mixed model. include whether individuals moved covariate, compare effect dispersal growth (testing whether dispersal beneficial ). Density factor now centered 1, intercept control pool (density factor 1). standardize growth across different streams, fish left different amounts time, analyse growth thirty days. also scale SL, intercept refer 0 length, average length. Stream_ID included random factor account differences slope, shading etc. factor accounts sequence authors measured fish included rule biases SL measure. Model selection (continous density) Smaller individuals stay grow compared larger ones, hence negative effect initial standard length. Among individuals stay, higher densities cause growth lower. Individuals disperse lower growth compared stay, small. Larger individuals disperse (treatment), hand, grow . make sure missing non-linear effects treatment, run model density expressed factor (treatment). Model selection (factorial treatments) treatment included factor variable, best fit model changes. AIC difference though > 4, pick model density continuous factor. plots visualize results.  Plotted left , y axis, residual growth values standard length alone ruled . done calculating predicted growth individuals given standard length.","code":"cr_table %<>%   mutate(growth_30 = growth*30/as.numeric(interval)) cr_table %>%   filter(growth_30 > 10) ## # A tibble: 1 × 26 ##   markID streamID treatment sex_stage_0 patch_0 habitat_0  SL_0 weight_0 ##   <fct>  <fct>    <fct>     <chr>       <chr>   <fct>     <dbl>    <dbl> ## 1 6V7P   CL1      C         F           P16-22  E          18.0      0.1 ## # ℹ 18 more variables: releaseDate <date>, marker_0 <chr>, patch_1 <fct>, ## #   habitat_1 <fct>, sex_stage_1 <chr>, SL_1 <dbl>, weight_1 <dbl>, ## #   captureDate <date>, marker_1 <chr>, pool_treat_0 <chr>, pool_treat_1 <chr>, ## #   moved <lgl>, hshift <lgl>, interval <drtn>, growth <dbl>, ## #   density_factor <dbl>, marker_seq <chr>, growth_30 <dbl> # the individual recaptured after 9 days has a recorded growth which is unbelievable  # when extrapolated. This can be due to undermeasuring, followed by overmeasuring, # and then extrapolated from the early growth. I will remove this individual. cr_table %<>%   filter(growth_30 < 10) %>%   mutate(SL_0s = scale(SL_0))  g0 <- lmer(growth_30 ~ SL_0s*moved*density_factor  +                    (1|streamID) + (1|marker_seq),                 data = cr_table %>% filter(sex_stage_0 == \"I\"),                 na.action = na.omit) # the three way interaction is not significant and can be dropped g1 <- lmer(growth_30 ~ (SL_0s+moved+density_factor)^2 +                    (1|streamID) + (1|marker_seq),                 data = cr_table,                 na.action = na.omit) # dropping SL x density g2 <- lmer(growth_30 ~ SL_0s*moved + moved*density_factor +                    (1|streamID) + (1|marker_seq),                 data = cr_table,                 na.action = na.omit) # dropping moved x density g3 <- lmer(growth_30 ~ SL_0s*moved + density_factor +                    (1|streamID) + (1|marker_seq),                 data = cr_table,                 na.action = na.omit) # stargazer needs objects that belong to lmer class, not lmerTest class(g0) <- class(g1) <- class(g2) <- class(g3) <- \"lmerMod\" stargazer::stargazer(g0, g1, g2, g3,                      type = \"html\", report = ('vcp*'),                      title  = \"Model selection (continous density)\",                      dep.var.labels = 'Growth (mm/month)',                      column.sep.width = \"10pt\",                      omit.stat = c(\"bic\"),                      star.char = c('.', '*', '**')) g0b <- lmer(growth_30 ~ SL_0s*moved*treatment +                    (1|streamID) + (1|marker_seq),                 data = cr_table,                 na.action = na.omit) # 3-way can be dropped g1b <- lmer(growth_30 ~ (SL_0s+moved+treatment)^2 +                    (1|streamID) + (1|marker_seq),                 data = cr_table,                 na.action = na.omit) class(g0b) <- class(g1b) <- \"lmerMod\" stargazer::stargazer(g0b, g1b,                      type = \"html\", report = ('vcp*'),                      title  = \"Model selection (factorial treatments)\",                      dep.var.labels = 'Growth (mm/month)',                      column.sep.width = \"10pt\",                      omit.stat = c(\"bic\"),                      star.char = c('.', '*', '**')) AIC(g3, g1b) ##     df      AIC ## g3   8 961.2237 ## g1b 13 966.1466 alpha <- summary(g3)$coefficients[\"(Intercept)\", \"Estimate\"] b_size <- summary(g3)$coefficients[\"SL_0s\", \"Estimate\"]  cr_table %<>%   mutate(pred_growth = alpha + b_size*SL_0s,          res = growth_30 - pred_growth) alt_data <- cr_table %>%   mutate(treatment = plyr::mapvalues(treatment,                                      c(\"D\", \"C\", \"I\"),                                      c(\"decreased\", \"control\", \"increased\")),          treatment = factor(treatment, levels=c(\"decreased\", \"control\", \"increased\")),          boxplot_position = case_when(            treatment == \"decreased\" ~ -0.5,            treatment == \"control\" ~ 0,            treatment == \"increased\" ~ 0.5          ))  pres <- ggplot(alt_data,                 aes(x = density_factor, y = res, group = treatment)) +   geom_hline(yintercept = 0,               linetype = \"dashed\",               linewidth = 0.4) +   ylab(\"Growth residuals\") + xlab(\"Proportional change in density\") +   geom_boxplot(aes(x = boxplot_position,                    y = res,                    fill = treatment),                alpha = 0.5,                outliers = F,                coef = 0) +   geom_jitter(aes(shape=treatment,                    fill = treatment),                position=position_jitter(0.03),                alpha = .75) +   scale_shape_manual(values = c(25, 22, 24)) +   scale_x_continuous(breaks = c(-0.5, 0, 0.5)) +   scale_fill_manual(values = c(\"#ffb14e\", \"#cd34b5\", \"#0000ff\")) +   #scale_color_manual(values = c(\"#ffb14e\", \"#cd34b5\", \"#0000ff\")) +   theme_bw() +   theme(legend.position = \"inside\",         legend.position.inside = c(0.80,0.85),          legend.background = element_rect(fill = \"transparent\"),         plot.margin = unit(c(0.5,1.5,0.5,1), \"lines\"))  # now plotting size x moved interaction on growth sls <- modelr::seq_range(cr_table$SL_0, n = 50) ds <- 0 mv <- c(FALSE, TRUE)  newdata <- expand.grid(SL_0 = sls,                        moved = mv,                        density_factor = ds) %>%   mutate(SL_0s = (SL_0 - attr(cr_table$SL_0s, \"scaled:center\"))/                     attr(cr_table$SL_0s, \"scaled:scale\"),          dispersed = plyr::mapvalues(moved,                                      c(TRUE, FALSE),                                      c(\"YES\", \"NO\")),          dispersed = factor(dispersed))  newdata %<>%   add_column(pred = predict(g3, newdata = newdata, re.form = ~0))  alt_data <- cr_table %>%   mutate(dispersed = plyr::mapvalues(moved,                                      c(TRUE, FALSE),                                      c(\"YES\", \"NO\")),          dispersed = factor(dispersed))  plen <- ggplot(alt_data, aes(x = SL_0, y = growth_30, group)) +   ylab(\"Growth (mm/month)\") + xlab(\"Initial standard length (mm)\") +   geom_point(alpha = .75, aes(shape = dispersed,                              col = dispersed)) +   geom_line(data = newdata, aes(x = SL_0, y = pred,                                  linetype = dispersed,                                 color = dispersed),             size = 0.5) +   scale_shape_manual(values = c(21, 8)) +   scale_color_manual(values = c(\"#fa8775\", \"#9d02d7\")) +   theme_bw() +   theme(legend.position = \"inside\",     legend.position.inside = c(0.85, .85),       legend.background = element_rect(fill = \"transparent\"),     plot.margin = unit(c(0.5,1.5,0.5,1), \"lines\")) ## Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0. ## ℹ Please use `linewidth` instead. ## This warning is displayed once every 8 hours. ## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was ## generated. ggarrange(pres, plen, labels = c(\"a\", \"b\")) jpeg(file.path(here::here(), \"vignettes\", \"figures\", \"growth_by_treatment_and_dispersal.jpeg\"),      width = 8, height = 4.5, units = \"in\", res = 400) ggarrange(pres, plen, labels = c(\"a\", \"b\")) dev.off() ## agg_png  ##       2"},{"path":"https://sebastianodebona.github.io/guppyDme/articles/DME-020_Density_dependence.html","id":"growth-habitat-change","dir":"Articles","previous_headings":"Growth","what":"Growth & Habitat change","title":"Density dependence","text":"might interesting check effects habitat shift growth individuals remain. might expect individuals moved different habitat grow . opposite true, suggest individuals forced suboptimal habitats paying consequences terms growth. Let’s plot data together predictions factorial treatment model.  Δ\\Delta AIC model density continuous treatment factor < 4, consider complex model. expected, control larger individuals change habitat grow less (- SL: p < 0.001). Individuals change habitat control treatment experience even smaller growth (- hshift: p = 0.031), especially large (- SL x hshift: p = 0.010). can due fact large individuals hold good quality microhabitats equilibrium conditions. Average sized individuals decreased treatment higher growth control increased density treatment, disperse. , makes sense given lower density provides weaker competition. Moreover, large individuals decreased density treatment benefit shifting habitat (SL x treatment x hshift: p = 0.013).","code":"# we'll try to model with density as a continuous variable first gh0 <- lmer(growth_30 ~ SL_0s*hshift*density_factor +                    (1|streamID) + (1|marker_seq),                 data = cr_table %>% filter(!moved),                 na.action = na.omit) # 3-way can go gh1 <- lmer(growth_30 ~ (SL_0s+hshift+density_factor)^2 +                    (1|streamID) + (1|marker_seq),                 data = cr_table %>% filter(!moved),                 na.action = na.omit) # hshift x density can go gh2 <- lmer(growth_30 ~ SL_0s*hshift+ SL_0s*density_factor +                    (1|streamID) + (1|marker_seq),                 data = cr_table %>% filter(!moved),                 na.action = na.omit) # SL x density gh3 <- lmer(growth_30 ~ SL_0s*hshift + density_factor +                    (1|streamID) + (1|marker_seq),                 data = cr_table %>% filter(!moved),                 na.action = na.omit) # SL x hshift gh4 <- lmer(growth_30 ~ SL_0s + hshift + density_factor +                    (1|streamID) + (1|marker_seq),                 data = cr_table %>% filter(!moved),                 na.action = na.omit)    # and With density as a factor gh0b <- lmer(growth_30 ~ SL_0s*treatment*hshift +                    (1|streamID) + (1|marker_seq),                 data = cr_table %>% filter(!moved),                 na.action = na.omit)  AIC(gh4, gh0b) ##      df      AIC ## gh4   7 778.8988 ## gh0b 15 782.1826 # the difference in AIC is small, so I will consider the most complex model summary(gh0b) ## Linear mixed model fit by REML. t-tests use Satterthwaite's method [ ## lmerModLmerTest] ## Formula: growth_30 ~ SL_0s * treatment * hshift + (1 | streamID) + (1 |   ##     marker_seq) ##    Data: cr_table %>% filter(!moved) ##  ## REML criterion at convergence: 752.2 ##  ## Scaled residuals:  ##     Min      1Q  Median      3Q     Max  ## -3.1127 -0.7251 -0.0225  0.6110  3.6448  ##  ## Random effects: ##  Groups     Name        Variance Std.Dev. ##  marker_seq (Intercept) 0.1942   0.4406   ##  streamID   (Intercept) 0.1630   0.4038   ##  Residual               1.1638   1.0788   ## Number of obs: 246, groups:  marker_seq, 5; streamID, 3 ##  ## Fixed effects: ##                              Estimate Std. Error        df t value Pr(>|t|)     ## (Intercept)                   0.86759    0.35551   5.65285   2.440   0.0529 .   ## SL_0s                        -1.21348    0.12845 231.02435  -9.447   <2e-16 *** ## treatmentD                    0.72305    0.30410 231.81885   2.378   0.0182 *   ## treatmentI                   -0.00949    0.33375 230.18717  -0.028   0.9773     ## hshiftTRUE                   -0.43937    0.20309 231.72551  -2.163   0.0315 *   ## SL_0s:treatmentD             -0.08930    0.28312 229.45298  -0.315   0.7527     ## SL_0s:treatmentI              0.13965    0.32286 230.28961   0.433   0.6658     ## SL_0s:hshiftTRUE             -0.53196    0.20665 230.94018  -2.574   0.0107 *   ## treatmentD:hshiftTRUE         0.31333    0.43338 232.04699   0.723   0.4704     ## treatmentI:hshiftTRUE         0.07731    0.40311 231.68950   0.192   0.8481     ## SL_0s:treatmentD:hshiftTRUE   0.81313    0.37166 230.09335   2.188   0.0297 *   ## SL_0s:treatmentI:hshiftTRUE   0.62011    0.40841 229.76495   1.518   0.1303     ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## Correlation of Fixed Effects: ##             (Intr) SL_0s  trtmnD trtmnI hsTRUE SL_0s:D SL_0s:I SL_0:T tD:TRU ## SL_0s       -0.116                                                           ## treatmentD  -0.193  0.107                                                    ## treatmentI  -0.157  0.144  0.173                                             ## hshiftTRUE  -0.268  0.172  0.355  0.253                                      ## SL_0s:trtmD  0.057 -0.444 -0.245 -0.059 -0.097                               ## SL_0s:trtmI  0.057 -0.411 -0.054 -0.540 -0.069  0.180                        ## SL_0s:hTRUE  0.037 -0.597 -0.055 -0.072 -0.159  0.265   0.239                ## trtmnD:TRUE  0.123 -0.074 -0.703 -0.118 -0.503  0.176   0.031   0.068        ## trtmnI:TRUE  0.133 -0.133 -0.183 -0.842 -0.499  0.059   0.460   0.090  0.256 ## SL_0:D:TRUE -0.023  0.337  0.198  0.047  0.117 -0.763  -0.138  -0.552 -0.285 ## SL_0:I:TRUE -0.021  0.307  0.044  0.414  0.088 -0.137  -0.777  -0.505 -0.046 ##             tI:TRU SL_0:D: ## SL_0s                      ## treatmentD                 ## treatmentI                 ## hshiftTRUE                 ## SL_0s:trtmD                ## SL_0s:trtmI                ## SL_0s:hTRUE                ## trtmnD:TRUE                ## trtmnI:TRUE                ## SL_0:D:TRUE -0.075         ## SL_0:I:TRUE -0.413  0.285 summary(gh4) ## Linear mixed model fit by REML. t-tests use Satterthwaite's method [ ## lmerModLmerTest] ## Formula: growth_30 ~ SL_0s + hshift + density_factor + (1 | streamID) +   ##     (1 | marker_seq) ##    Data: cr_table %>% filter(!moved) ##  ## REML criterion at convergence: 764.9 ##  ## Scaled residuals:  ##     Min      1Q  Median      3Q     Max  ## -3.2846 -0.6298 -0.0045  0.5820  2.7919  ##  ## Random effects: ##  Groups     Name        Variance Std.Dev. ##  marker_seq (Intercept) 0.1934   0.4398   ##  streamID   (Intercept) 0.1571   0.3963   ##  Residual               1.2262   1.1073   ## Number of obs: 246, groups:  marker_seq, 5; streamID, 3 ##  ## Fixed effects: ##                 Estimate Std. Error        df t value Pr(>|t|)     ## (Intercept)      0.94022    0.34297   5.37991   2.741   0.0377 *   ## SL_0s           -1.20859    0.07609 239.85239 -15.883  < 2e-16 *** ## hshiftTRUE      -0.24619    0.14986 239.84849  -1.643   0.1017     ## density_factor  -0.98639    0.24652 240.47139  -4.001 8.39e-05 *** ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## Correlation of Fixed Effects: ##             (Intr) SL_0s  hsTRUE ## SL_0s       -0.083               ## hshiftTRUE  -0.253  0.022        ## densty_fctr  0.026  0.000 -0.212 tts <- levels(cr_table$treatment) hs <- c(\"NO\", \"YES\")  newdata_hab <- expand.grid(SL_0 = sls,                        hshift = hs,                        treatment = tts) %>%   mutate(SL_0s = (SL_0 - attr(cr_table$SL_0s, \"scaled:center\"))/                     attr(cr_table$SL_0s, \"scaled:scale\"),          hshift = factor(hshift),          treatment_f = factor(treatment, levels = c(\"D\", \"C\", \"I\"))) %>%   add_column(hab_pred = predict(gh0b, newdata = ., re.form = ~0))    alt_data <- cr_table %>%   mutate(treatment_f = factor(treatment, levels = c(\"D\", \"C\", \"I\")),          hshift = plyr::mapvalues(hshift,                                   c(FALSE, TRUE),                                   c(\"NO\", \"YES\")),          hshift = factor(hshift, levels = levels(newdata_hab$hshift)))    labelss_treat <- c(\"D\" = \"decreased\",                    \"C\" = \"control\",                    \"I\" = \"increased\")  pgh <- ggplot(alt_data %>% filter(!is.na(hshift)), aes(x = SL_0, y = growth_30)) +   ylab(\"Growth (mm/month)\") + xlab(\"Initial standard length (mm)\") +   geom_point(alpha = 1,               aes(shape = hshift,                  color = hshift)) +   scale_shape_manual(values = c(21, 8)) +   geom_line(data = newdata_hab, aes(x = SL_0, y = hab_pred, linetype = hshift,                                     color = hshift),             size = 0.5) +   facet_grid( ~ treatment_f,                labeller = labeller(treatment_f = labelss_treat)) +   scale_color_manual(values = c(\"#fa8775\", \"#9d02d7\")) +   theme_bw() +   labs(linetype = \"microhabitat \\nshift\",        color = \"microhabitat \\nshift\",        shape = \"microhabitat \\nshift\") pgh jpeg(file.path(here::here(), \"vignettes\", \"figures\", \"growth_by_habitat_and_treatment.jpeg\"),      width = 7, height = 4, units = \"in\", res = 400) pgh dev.off() ## agg_png  ##       2"},{"path":[]},{"path":"https://sebastianodebona.github.io/guppyDme/articles/DME-020_Density_dependence.html","id":"condition-dispersal","dir":"Articles","previous_headings":"Condition","what":"Condition & Dispersal","title":"Density dependence","text":"even shorter-term measure fitness individual condition. time, idea evaluate fat content preserved guppies, now can use proxy condition ratio weight SL3. Pregnancy females complicates picture, since female might gain weight due development embryos. condition can assessed males immature females. just plotting weight length visualize relationship see crazy outliers need checked.  seems fine. concern , looking regression size-weight fish TM, many males juvenile males appear high weight. reported weight matches physical datasheets, ’s typographical error. can due masculinized females, found sometimes Taylor specifically. can now calculate condition, making sure remove mature females (whose estimated condition affected pregnancy). Since length mm weight grams, numbers small. multiply measures 103 turn measure unit mg/mm3. done growth, calculate difference condition 30 days. also calculate relative change condition 30 days, : condition1−condition0condition01interval \\frac{condition_1 - condition_0}{condition_0} \\frac{1}{interval}   can now test effect density condition. adopt stepwise model simplification removing non-significant interactions main effects, done far. Model selection (factorial treatments) best model predicts condition differential negative individuals disperse. means , average, individual likely decrease body condition dispersing. result makes sense considering costly dispersal can . Moreover, large individuals smaller gains condition, significantly. trend observed seems mostly determined happens control treatment (datapoints together). , can run model treatment categorical variable check asymmetries. factorial treatment shows different results. Δ\\DeltaAIC two models quite drastic (> 80), model density continuous provides better fit.  plot results treatment considered factor (model discarded according AIC values).  order prove dispersal decreases condition, individual lower condition disperse, run model initial condition explanatory variable, dispersal response. tried model interaction sex_stage condition, interaction significant. already know males likely disperse immature individuals, need keep sex fixed effect. Initial condition significantly affects dispersal, individuals good condition likely disperse. Let’s now see dispersal affects final condition. tested interaction moved initial condition, main effect initial condition, significant (even initial condition alone model). Density also significant effect condition. Dispersal significant negative effect final condition.","code":"labelss_recap <- c(\"0\" = \"capture\",                    \"1\" = \"recapture\")  ggplot(data %>% filter(!is.na(sex_stage), streamID != \"TM\"),        aes(x = as.numeric(SL), y = weight, color = sex_stage)) +    geom_point(alpha = 0.2) +    scale_colour_manual(values = c(\"#1E88E5\", \"#FFC107\", \"#004D40\")) +   xlab(\"Standard length (mm)\") + ylab(\"Weight (g)\") +    facet_grid(~recap, labeller = labeller(recap = labelss_recap)) ## Warning in FUN(X[[i]], ...): NAs introduced by coercion ## Warning: Removed 970 rows containing missing values or values outside the scale range ## (`geom_point()`). cr_table %<>%   mutate(condition_0 = ifelse(sex_stage_0 %in% c(\"I\", \"M\"),                                weight_0*1000/(SL_0^3),                               NA),          condition_1 = ifelse(sex_stage_1 %in% c(\"I\", \"M\"),                                weight_1*1000/(SL_1^3),                               NA),          cond_diff = condition_1-condition_0,          cond_diff_30 = cond_diff*30/as.numeric(interval),          rel_cond_change = (condition_1-condition_0)/(condition_0*as.numeric(interval)))  hist(cr_table$cond_diff_30) hist(cr_table$rel_cond_change) c0 <- lmer(cond_diff_30 ~ SL_0s * density_factor * moved +                    (1|marker_seq) + (1|streamID),                  data = cr_table,                  na.action = na.omit) # I can remove the 3-way interaction c1 <- lmer(cond_diff_30 ~ (SL_0s + density_factor + moved)^2 +                    (1|marker_seq) + (1|streamID),                  data = cr_table,                  na.action = na.omit) # density x moved can be removed too c2 <- lmer(cond_diff_30 ~ SL_0s*density_factor + SL_0s*moved +                      (1|marker_seq) + (1|streamID),                  data = cr_table,                  na.action = na.omit) # density x SL c3 <- lmer(cond_diff_30 ~ SL_0s  + SL_0s*moved +                      (1|marker_seq) + (1|streamID),                  data = cr_table,                  na.action = na.omit) # SL x moved c4 <- lmer(cond_diff_30 ~ SL_0s + density_factor + moved +                      (1|marker_seq) + (1|streamID),                  data = cr_table,                  na.action = na.omit) # density c5 <- lmer(cond_diff_30 ~ SL_0s  + moved +                      (1|marker_seq) + (1|streamID),                  data = cr_table,                  na.action = na.omit) # size c6 <- lmer(cond_diff_30 ~  moved +                      (1|marker_seq) + (1|streamID),                  data = cr_table,                  na.action = na.omit) ## boundary (singular) fit: see help('isSingular') summary(c6) ## Linear mixed model fit by REML. t-tests use Satterthwaite's method [ ## lmerModLmerTest] ## Formula: cond_diff_30 ~ moved + (1 | marker_seq) + (1 | streamID) ##    Data: cr_table ##  ## REML criterion at convergence: -489.1 ##  ## Scaled residuals:  ##     Min      1Q  Median      3Q     Max  ## -2.7823 -0.5085 -0.0766  0.5722  2.4954  ##  ## Random effects: ##  Groups     Name        Variance  Std.Dev. ##  marker_seq (Intercept) 2.621e-06 0.001619 ##  streamID   (Intercept) 0.000e+00 0.000000 ##  Residual               9.006e-06 0.003001 ## Number of obs: 59, groups:  marker_seq, 4; streamID, 3 ##  ## Fixed effects: ##               Estimate Std. Error         df t value Pr(>|t|)     ## (Intercept)  0.0036612  0.0009591  3.6081816   3.817 0.022737 *   ## movedTRUE   -0.0033462  0.0008420 54.9251497  -3.974 0.000208 *** ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## Correlation of Fixed Effects: ##           (Intr) ## movedTRUE -0.319 ## optimizer (nloptwrap) convergence code: 0 (OK) ## boundary (singular) fit: see help('isSingular') class(c0) = class(c1) = class(c2) = class(c3) = class(c4) = class(c5) = class(c6) <- \"lmerMod\" stargazer::stargazer(c0, c1, c2, c3, c4, c5, c6,                      type = \"html\", report = ('vcp*'),                      title  = \"Model selection (factorial treatments)\",                      dep.var.labels = 'Condition (mg/mm^3)',                      column.sep.width = \"10pt\",                      omit.stat = c(\"bic\"),                      star.char = c('.', '*', '**')) c0b <- lmer(cond_diff_30 ~ SL_0s * treatment * moved +                    (1|marker_seq) + (1|streamID),                  data = cr_table,                  na.action = na.omit) # here a bunch of interactions are significant summary(c0b) ## Linear mixed model fit by REML. t-tests use Satterthwaite's method [ ## lmerModLmerTest] ## Formula: cond_diff_30 ~ SL_0s * treatment * moved + (1 | marker_seq) +   ##     (1 | streamID) ##    Data: cr_table ##  ## REML criterion at convergence: -410.6 ##  ## Scaled residuals:  ##      Min       1Q   Median       3Q      Max  ## -1.70001 -0.57871 -0.06693  0.66484  2.07960  ##  ## Random effects: ##  Groups     Name        Variance  Std.Dev.  ##  marker_seq (Intercept) 2.962e-06 0.0017209 ##  streamID   (Intercept) 3.761e-07 0.0006133 ##  Residual               6.686e-06 0.0025858 ## Number of obs: 59, groups:  marker_seq, 4; streamID, 3 ##  ## Fixed effects: ##                              Estimate Std. Error         df t value Pr(>|t|)    ## (Intercept)                 6.329e-04  1.721e-03  2.127e+01   0.368  0.71671    ## SL_0s                      -6.897e-03  2.084e-03  4.436e+01  -3.309  0.00186 ** ## treatmentD                  1.186e-03  2.576e-03  4.311e+01   0.460  0.64764    ## treatmentI                  1.939e-03  1.876e-03  4.500e+01   1.034  0.30685    ## movedTRUE                   7.763e-05  2.344e-03  4.578e+01   0.033  0.97372    ## SL_0s:treatmentD            6.466e-03  3.587e-03  4.361e+01   1.802  0.07838 .  ## SL_0s:treatmentI            7.509e-03  3.481e-03  4.448e+01   2.157  0.03644 *  ## SL_0s:movedTRUE             1.471e-02  5.619e-03  4.525e+01   2.617  0.01202 *  ## treatmentD:movedTRUE       -3.967e-04  3.475e-03  3.815e+01  -0.114  0.90971    ## treatmentI:movedTRUE       -5.706e-04  3.169e-03  4.426e+01  -0.180  0.85794    ## SL_0s:treatmentD:movedTRUE -1.639e-02  7.097e-03  4.481e+01  -2.309  0.02562 *  ## SL_0s:treatmentI:movedTRUE -1.258e-02  7.767e-03  4.406e+01  -1.620  0.11240    ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## Correlation of Fixed Effects: ##             (Intr) SL_0s  trtmnD trtmnI mvTRUE SL_0s:D SL_0s:I SL_0:T tD:TRU ## SL_0s        0.750                                                           ## treatmentD  -0.401 -0.435                                                    ## treatmentI  -0.641 -0.691  0.341                                             ## movedTRUE   -0.539 -0.568  0.310  0.437                                      ## SL_0s:trtmD -0.406 -0.549  0.862  0.354  0.322                               ## SL_0s:trtmI -0.438 -0.569  0.248  0.811  0.265  0.298                        ## SL_0s:mTRUE -0.330 -0.386  0.167  0.259  0.794  0.212   0.182                ## trtmnD:TRUE  0.324  0.333 -0.756 -0.237 -0.653 -0.651  -0.150  -0.513        ## trtmnI:TRUE  0.370  0.404 -0.223 -0.537 -0.711 -0.225  -0.422  -0.561  0.472 ## SL_0:D:TRUE  0.253  0.290 -0.438 -0.194 -0.612 -0.510  -0.139  -0.778  0.594 ## SL_0:I:TRUE  0.211  0.257 -0.120 -0.345 -0.530 -0.135  -0.421  -0.688  0.358 ##             tI:TRU SL_0:D: ## SL_0s                      ## treatmentD                 ## treatmentI                 ## movedTRUE                  ## SL_0s:trtmD                ## SL_0s:trtmI                ## SL_0s:mTRUE                ## trtmnD:TRUE                ## trtmnI:TRUE                ## SL_0:D:TRUE  0.421         ## SL_0:I:TRUE  0.815  0.527 AIC(c3, c0b) ##     df       AIC ## c3   7 -460.8564 ## c0b 15 -380.5707 cdp <- ggplot(cr_table, aes(x = moved,                              y = cond_diff_30,                             fill = moved)) +   geom_boxplot(coef = 0,                outliers = FALSE,                alpha = 0.75) +   xlab(\"Dispersal\") + ylab(\"Relative change in condition\") +   ylim(c(-0.01, 0.015)) +   geom_jitter(shape=21, position=position_jitter(0.02), alpha = 0.75) +   scale_x_discrete(labels = c(\"NO\", \"YES\")) +   scale_fill_manual(values = c(\"#fa8775\", \"#9d02d7\")) +   geom_segment(aes(x = 1, xend = 2, y = 0.013, yend = 0.013), color = \"black\") +   annotate(\"text\", x = 1.5, y = 0.0135, label = \"*\", size = 6) +   theme_bw() +   theme(plot.margin = unit(c(0.5,1.5,0.5,1),                            \"lines\"),         legend.position = \"none\")  cdp ## Warning: Removed 302 rows containing non-finite outside the scale range ## (`stat_boxplot()`). ## Warning: Removed 302 rows containing missing values or values outside the scale range ## (`geom_point()`). # jpeg(file.path(here::here(), \"vignettes\", \"condition_dispersal.jpeg\"), #      width = 3, height = 3.5, units = \"in\", res = 400) # cdp # dev.off() newdata_cond <- expand.grid(SL_0 = sls,                             treatment = tts,                             moved = mv) %>%   mutate(SL_0s = (SL_0 - attr(cr_table$SL_0s, \"scaled:center\"))/                     attr(cr_table$SL_0s, \"scaled:scale\"),          moved = factor(moved),          treatment_f = factor(treatment, levels = c(\"D\", \"C\", \"I\"))) %>%   add_column(c_pred = predict(c0b, newdata = ., re.form = ~ 0))  p <- ggplot(cr_table %>% filter(sex_stage_1 %in% c(\"I\", \"M\")),        aes(x = SL_0, y = cond_diff_30)) +   xlim(12, 21) +   ylab(bquote(\"Change in condition (\" ~ mm/mg^3~\")\")) + xlab(\"Initial standard length (mm)\") +   geom_point(alpha = .5, aes(colour = streamID, shape = moved)) +   scale_color_manual(values=c(\"#DAA323\", \"#691E92\", \"#199958\")) +   scale_shape_manual(values = c(16, 8)) +   geom_line(data = newdata_cond, aes(x = SL_0, y = c_pred, linetype = moved), size = 0.5) +   facet_grid( ~ treatment_f,                labeller = labeller(treatment_f = labelss_treat)) +   ggtitle(\"Effect of density and dispersal on condition\") annotate_figure(p, top = text_grob(\"This  model  was  rejected (Delta AIC >> 4)\",                                    color = \"red\", vjust = 7, size = 14)) ## Warning: Removed 186 rows containing missing values or values outside the scale range ## (`geom_point()`). ## Warning: Removed 58 rows containing missing values or values outside the scale range ## (`geom_line()`). # first, I am testing whether initial condition affects dispersal c_d <- glmer(moved ~ condition_0 +                    (1|marker_0) + (1|streamID),              data = cr_table,              family = \"binomial\",              na.action = na.omit) ## boundary (singular) fit: see help('isSingular') summary(c_d) ## Generalized linear mixed model fit by maximum likelihood (Laplace ##   Approximation) [glmerMod] ##  Family: binomial  ( logit ) ## Formula: moved ~ condition_0 + (1 | marker_0) + (1 | streamID) ##    Data: cr_table ##  ##      AIC      BIC   logLik deviance df.resid  ##    138.3    149.2    -65.1    130.3      109  ##  ## Scaled residuals:  ##     Min      1Q  Median      3Q     Max  ## -1.3678 -0.7174 -0.5020  0.9908  5.4232  ##  ## Random effects: ##  Groups   Name        Variance Std.Dev. ##  streamID (Intercept) 0        0        ##  marker_0 (Intercept) 0        0        ## Number of obs: 113, groups:  streamID, 3; marker_0, 2 ##  ## Fixed effects: ##             Estimate Std. Error z value Pr(>|z|)    ## (Intercept)   -5.543      1.714  -3.234  0.00122 ** ## condition_0  277.980     95.868   2.900  0.00374 ** ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## Correlation of Fixed Effects: ##             (Intr) ## condition_0 -0.992 ## optimizer (Nelder_Mead) convergence code: 0 (OK) ## boundary (singular) fit: see help('isSingular') d_c <- lmer(condition_1 ~ moved +                    (1|marker_0) + (1|streamID),                  data = cr_table,                  na.action = na.omit) ## boundary (singular) fit: see help('isSingular') summary(d_c) ## Linear mixed model fit by REML. t-tests use Satterthwaite's method [ ## lmerModLmerTest] ## Formula: condition_1 ~ moved + (1 | marker_0) + (1 | streamID) ##    Data: cr_table ##  ## REML criterion at convergence: -592.3 ##  ## Scaled residuals:  ##      Min       1Q   Median       3Q      Max  ## -2.95123 -0.62091 -0.04051  0.49032  2.42803  ##  ## Random effects: ##  Groups   Name        Variance  Std.Dev.  ##  streamID (Intercept) 5.087e-07 0.0007132 ##  marker_0 (Intercept) 0.000e+00 0.0000000 ##  Residual             2.570e-06 0.0016033 ## Number of obs: 62, groups:  streamID, 3; marker_0, 2 ##  ## Fixed effects: ##               Estimate Std. Error         df t value Pr(>|t|)     ## (Intercept)  0.0200976  0.0004906  2.5829428  40.968 0.000105 *** ## movedTRUE   -0.0009452  0.0004304 58.2300173  -2.196 0.032094 *   ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## Correlation of Fixed Effects: ##           (Intr) ## movedTRUE -0.297 ## optimizer (nloptwrap) convergence code: 0 (OK) ## boundary (singular) fit: see help('isSingular') conds <- data.frame(condition_0 = modelr::seq_range(cr_table$condition_0, n = 50)) %>%   add_column(predicted = plogis(predict(c_d, newdata = ., re.form = ~0)))  c_dplot <- ggplot(   cr_table,    aes(x = condition_0,        y = as.numeric(moved))) +   geom_point(position = position_jitter(height = 0.03),              alpha = 0.75) +   geom_line(data = conds, aes(x = condition_0, y = predicted)) +   xlab(bquote(\"Initial condition (\"~mm/mg^3~\")\")) + ylab(\"Dispersal probability\") +   theme_bw() +   theme(plot.margin = unit(c(0.5,1.5,0.5,1), \"lines\"))  d_cplot <- ggplot(cr_table, aes(x = moved, y = condition_1)) +   geom_boxplot(coef = 0) +    ylim(0.012, 0.026) +   ylab(bquote(\"Final condition (\"~mm/mg^3~\")\")) +   xlab(\"Dispersed\") +    geom_segment(aes(x = 1, xend = 2, y = 0.025, yend = 0.025)) +   annotate(\"text\", x = 1.5, y = 0.0255, label = \"*\", size = 6) +   theme_bw() +   theme(plot.margin = unit(c(0.5,1.5,0.5,1), \"lines\"))  ggarrange(c_dplot, d_cplot, labels = c(\"a\", \"b\")) ## Warning: Removed 248 rows containing missing values or values outside the scale range ## (`geom_point()`). ## Warning in geom_segment(aes(x = 1, xend = 2, y = 0.025, yend = 0.025)): All aesthetics have length 1, but the data has 361 rows. ## ℹ Please consider using `annotate()` or provide this layer with data containing ##   a single row. ## Warning: Removed 282 rows containing non-finite outside the scale range ## (`stat_boxplot()`). # Plotting change in condition with dispersal and effect of initial condition on dispersal ggarrange(cdp, c_dplot, labels = c(\"a\", \"b\")) ## Warning: Removed 302 rows containing non-finite outside the scale range ## (`stat_boxplot()`). ## Warning: Removed 302 rows containing missing values or values outside the scale range ## (`geom_point()`). ## Warning: Removed 248 rows containing missing values or values outside the scale range ## (`geom_point()`). jpeg(file.path(here::here(), \"vignettes\", \"figures\", \"condition_by_dispersal.jpeg\"),      width = 6, height = 3.5, units = \"in\", res = 400) ggarrange(cdp, c_dplot, labels = c(\"a\", \"b\")) ## Warning: Removed 302 rows containing non-finite outside the scale range ## (`stat_boxplot()`). ## Warning: Removed 302 rows containing missing values or values outside the scale range ## (`geom_point()`). ## Warning: Removed 248 rows containing missing values or values outside the scale range ## (`geom_point()`). dev.off() ## agg_png  ##       2"},{"path":"https://sebastianodebona.github.io/guppyDme/articles/DME-020_Density_dependence.html","id":"condition-habitat-change","dir":"Articles","previous_headings":"Condition","what":"Condition & Habitat change","title":"Density dependence","text":"condition , growth, run model observe short-term effects habitat change individuals disperse. models differ density continuous factor, Δ\\DeltaAIC large enough can pick one. former better fit model, consider . significant term interaction density habitat shift.  results intentionally left paper, since number analyses already limiting reducing scope study clear message.","code":"ch0 <-  lmer(cond_diff_30 ~ density_factor*hshift +                    (1|marker_seq) + (1|streamID),                  data = cr_table %>% filter(!moved),                  na.action = na.omit) ## boundary (singular) fit: see help('isSingular') summary(ch0) ## Linear mixed model fit by REML. t-tests use Satterthwaite's method [ ## lmerModLmerTest] ## Formula: cond_diff_30 ~ density_factor * hshift + (1 | marker_seq) + (1 |   ##     streamID) ##    Data: cr_table %>% filter(!moved) ##  ## REML criterion at convergence: -295.4 ##  ## Scaled residuals:  ##     Min      1Q  Median      3Q     Max  ## -1.8682 -0.5988 -0.1030  0.4259  2.4104  ##  ## Random effects: ##  Groups     Name        Variance  Std.Dev.  ##  marker_seq (Intercept) 5.044e-06 2.246e-03 ##  streamID   (Intercept) 1.799e-15 4.241e-08 ##  Residual               9.096e-06 3.016e-03 ## Number of obs: 39, groups:  marker_seq, 4; streamID, 3 ##  ## Fixed effects: ##                             Estimate Std. Error         df t value Pr(>|t|)   ## (Intercept)                0.0044640  0.0014048  4.4292973   3.178   0.0291 * ## density_factor             0.0023963  0.0025134 33.0538726   0.953   0.3473   ## hshiftTRUE                -0.0003129  0.0011419 32.3394696  -0.274   0.7858   ## density_factor:hshiftTRUE -0.0069605  0.0036671 32.7694319  -1.898   0.0665 . ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## Correlation of Fixed Effects: ##             (Intr) dnsty_ hsTRUE ## densty_fctr  0.184               ## hshiftTRUE  -0.395 -0.298        ## dnsty_:TRUE -0.166 -0.633 -0.121 ## optimizer (nloptwrap) convergence code: 0 (OK) ## boundary (singular) fit: see help('isSingular') # 3-way is not significant and there's too few datapoints. ch0b <- lmer(cond_diff_30 ~ (SL_0s + treatment + hshift)^2 +                    (1|marker_seq) + (1|streamID),                  data = cr_table %>% filter(!moved),                  na.action = na.omit) ## boundary (singular) fit: see help('isSingular') summary(ch0b) ## Linear mixed model fit by REML. t-tests use Satterthwaite's method [ ## lmerModLmerTest] ## Formula: cond_diff_30 ~ (SL_0s + treatment + hshift)^2 + (1 | marker_seq) +   ##     (1 | streamID) ##    Data: cr_table %>% filter(!moved) ##  ## REML criterion at convergence: -257.1 ##  ## Scaled residuals:  ##      Min       1Q   Median       3Q      Max  ## -1.38934 -0.54046  0.06346  0.32927  2.26504  ##  ## Random effects: ##  Groups     Name        Variance  Std.Dev. ##  marker_seq (Intercept) 6.120e-06 0.002474 ##  streamID   (Intercept) 0.000e+00 0.000000 ##  Residual               5.107e-06 0.002260 ## Number of obs: 39, groups:  marker_seq, 4; streamID, 3 ##  ## Fixed effects: ##                        Estimate Std. Error        df t value Pr(>|t|)     ## (Intercept)           -0.006871   0.003176 26.969424  -2.163  0.03954 *   ## SL_0s                 -0.017661   0.004311 26.626882  -4.097  0.00035 *** ## treatmentD             0.008366   0.003375 26.065258   2.479  0.01998 *   ## treatmentI             0.009081   0.002759 26.189681   3.291  0.00285 **  ## hshiftTRUE             0.009188   0.003013 26.145689   3.049  0.00520 **  ## SL_0s:treatmentD       0.015661   0.005327 26.409273   2.940  0.00674 **  ## SL_0s:treatmentI       0.005148   0.003229 26.876563   1.594  0.12253     ## SL_0s:hshiftTRUE       0.013378   0.004535 26.471650   2.950  0.00657 **  ## treatmentD:hshiftTRUE  0.001341   0.004181 27.356815   0.321  0.75088     ## treatmentI:hshiftTRUE -0.009318   0.002935 26.439576  -3.175  0.00379 **  ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## Correlation of Fixed Effects: ##             (Intr) SL_0s  trtmnD trtmnI hsTRUE SL_0:D SL_0:I SL_0:T tD:TRU ## SL_0s        0.892                                                         ## treatmentD  -0.736 -0.778                                                  ## treatmentI  -0.719 -0.742  0.639                                           ## hshiftTRUE  -0.815 -0.858  0.736  0.662                                    ## SL_0s:trtmD -0.722 -0.809  0.916  0.601  0.695                             ## SL_0s:trtmI -0.141 -0.155  0.110  0.275 -0.084  0.125                      ## SL_0s:hTRUE -0.807 -0.907  0.712  0.623  0.939  0.734 -0.078               ## trtmnD:TRUE -0.434 -0.518  0.463  0.296  0.422  0.665  0.034  0.559        ## trtmnI:TRUE  0.554  0.569 -0.528 -0.776 -0.728 -0.461  0.258 -0.624 -0.180 ## optimizer (nloptwrap) convergence code: 0 (OK) ## boundary (singular) fit: see help('isSingular') AIC(ch0, ch0b) ##      df       AIC ## ch0   7 -281.4055 ## ch0b 13 -231.1079 labelss_hab <- c(\"FALSE\" = \"SAME HABITAT\",                    \"TRUE\" = \"CHANGED HABITAT\")  chp <- ggplot(cr_table %>% filter(!moved, !is.na(hshift)),         aes(x = density_factor, y = cond_diff_30, colour = treatment)) +   geom_hline(yintercept = 0, linetype = \"dashed\", size = 0.4) +   geom_boxplot() +   ylab(\"difference in condition (mm)\") + xlab(\"density multiplier\") +   geom_jitter(shape=16, position=position_jitter(0.02), alpha = .5) +   facet_grid( ~ hshift, labeller = labeller(hshift = labelss_hab)) +   ggtitle(\"Effect of density and habitat change on condition\")  chp ## Warning: Removed 246 rows containing non-finite outside the scale range ## (`stat_boxplot()`). ## Warning: Removed 246 rows containing missing values or values outside the scale range ## (`geom_point()`)."},{"path":"https://sebastianodebona.github.io/guppyDme/articles/DME-020_Density_dependence.html","id":"pool-level-recruitment","dir":"Articles","previous_headings":"","what":"Pool-level Recruitment","title":"Density dependence","text":"data female reproductive allocation published study. proxy can look recruitment pool-level, number newborn (<10 mm) recruited given number adults. give much information female reproductive output (since time capture recapture seldom enough female get pregnant produce offspring), rather give idea early-life mortality. calculate number adults captured “control”, “decreased” “increased” pool, number babies pools, establish equilibrium “recruitment” proportion babies per adult pool. pool, recruitment R0=rcapturedacapturedR_0 = \\frac{r_{captured}}{a_{captured}}, rcapturedr_{captured} acaptureda_{captured} correspond number new recruits (individuals < 10 mm) adults captured pool first capture, respectively. calculate recruitment proxy experiment (R1R_1) ratio number number new recruits (< 10 mm) recaptured experiment ended (rrecapturedr_{recaptured}) number adults released pools part experimental density manipulation (areleaseda_{released}). excludes individuals removed decreased pool, includes extra-limital individuals added increased pool. Note: calculating standard error difference recruitment, ’ll make assumptions, since sample case single number. order calculate variance difference recruitment, defined Var(R1−R0)=Var(rrecapturedareleased−rcapturedacaptured)Var(R_1 - R_0) = Var(\\frac{r_{recaptured}}{a_{released}} - \\frac{r_{captured}}{a_{captured}}) need assume covariance R1R_1 R0R_0 0, since estimated single ratio. , Var(R1−R0)≈Var(R1)+Var(R0) Var(R_1 - R_0) \\approx Var(R_1) + Var(R_0) addition, use Delta approximation calculate variance, Var(R)=Var(ra)≈1a2Var(r)+a2r4Var() Var(R) = Var(\\frac{r}{}) \\approx \\frac{1}{^2} Var(r) + \\frac{^2}{r^4}Var()  third assumption count data (number recruits number adults) Poisson distributed, making $$ Var(r) = E(r)\\newline Var() = E() $$ can now plot visualize proportional recruitment , different treatments. Keep mind “recruitment” simply ratio individuals <10 mm adult individuals.  important comment made : stated , number babies recapture divided number adults released capture. necessarily equal number adults recaptured, since individual might left habitat patch, dispersing away. done avoid confounding two things: effects density terms dispersal (individuals might trigger dispersal) effects density recruitment. can run simple model see trend significant (despite datapoints). Recruitment significantly lower higher density, expect.","code":"recruits <- data %>%   # only manipulated streams   filter(streamID %in% c(\"CL1\", \"CL2\", \"TL\")) %>%   group_by(streamID, patchID) %>%   # we include all individuals captured in a given pool in the accounting of initial recruitment   summarise(adults_0 = sum(!isbabyMark & recap == 0 &                               treatment %in% c(\"C\", \"D\", \"I\", \"R\", \"XR\", \"X\")),             babies_0 = sum(isbabyMark & recap == 0 &                               treatment %in% c(\"C\", \"D\", \"I\", \"R\", \"XR\", \"X\")),             adults_1 = sum(!isbabyMark & recap == 0 & treatment %in% c(\"C\", \"D\", \"I\")),             babies_1 = sum(isbabyMark & recap == 1)) %>%   filter(!is.na(patchID), adults_0 > 0) ## `summarise()` has grouped output by 'streamID'. You can override using the ## `.groups` argument. # the increased density pools are missing the added extralimital individuals # first, I will assign to each pool its treatment patch_to_treat <- data %>%   filter(recap == 0, treatment %in% c(\"I\", \"C\", \"D\")) %>%   group_by(streamID, patchID, treatment) %>%   summarise ## `summarise()` has grouped output by 'streamID', 'patchID'. You can override ## using the `.groups` argument. # I can now add the treatment info to the recruits table recruits <- left_join(patch_to_treat, recruits) ## Joining with `by = join_by(streamID, patchID)` # Now, I can count how many adults were added to the increased pool in each stream introduced <- data %>%   filter(treatment == \"E\", !isbabyMark) %>%   group_by(streamID) %>%   summarise(introduced = n())  # now I can merge this, and add the individuals to the introduced pool # then I can calculate the proportional recruitment # and the error recruits %<>%   right_join(introduced) %>%   mutate(adults_1 = ifelse(treatment == \"I\", adults_1 + introduced, adults_1)) %>%   select(-introduced) %>%   mutate(recruit_0 = babies_0/adults_0,          recruit_1 = babies_1/adults_1,          recruit_0_var = babies_0/(adults_0^2) + babies_0/(adults_0^3),          recruit_1_var = babies_1/(adults_1^2) + babies_1/(adults_1^3),          SE = sqrt(recruit_1_var + recruit_0_var)) ## Joining with `by = join_by(streamID)` # last step, including the information on density as continuous factor # instead of categorical variables recruits <- left_join(treatment_tab%>%select(-patchID),recruits) %>%   arrange(streamID, density_factor) %>%   mutate(treatment = str_replace_all(treatment,                                  c(\"D\" = \"decreased\",                                    \"C\" = \"control\",                                    \"I\" = \"increased\")),          treatment = factor(treatment, levels = c(\"decreased\", \"control\", \"increased\")),          stream = plyr::mapvalues(streamID,                                         c(\"CL1\", \"CL2\", \"TL\"),                                         c(\"Caigual 1\", \"Caigual 2\", \"Taylor\")),          # recentering the density factor          density_factor = density_factor - 1) ## Joining with `by = join_by(streamID, treatment)` pr <- ggplot(recruits,               aes(x = density_factor,                   y = recruit_1 - recruit_0,                   group = stream,                  color = stream)) +   geom_point(aes(shape = stream),               size = 2.5,              position = position_dodge(0.02)) +   geom_path(aes(linetype = stream)) +   ylim(-.5, .6) +   geom_errorbar(aes(ymin = recruit_1 - recruit_0 - SE, ymax = recruit_1 - recruit_0 + SE),                 width = 0.0,                 position = position_dodge(0.02)) +   scale_x_continuous(breaks = c(-0.5, 0., 0.5)) +   scale_shape_manual(values = c(16,17,15)) +   scale_color_manual(values=c(\"#DAA323\", \"#691E92\", \"#199958\")) +   labs(y = \"Recruitment difference (± SE)\", x = \"Poportional change in density\",         color = \"Stream\", linetype = \"Stream\", shape = \"Stream\") +   theme_bw()  pr jpeg(file.path(here::here(), \"vignettes\", \"figures\", \"pool_level_recruitment.jpeg\"),      width = 5, height = 3.5, units = \"in\", res = 400) pr dev.off() ## agg_png  ##       2 summary(r_model0 <- lm(I(recruit_1 - recruit_0) ~ density_factor, data = recruits)) ##  ## Call: ## lm(formula = I(recruit_1 - recruit_0) ~ density_factor, data = recruits) ##  ## Residuals: ##      Min       1Q   Median       3Q      Max  ## -0.18549 -0.07923 -0.03814  0.06001  0.34895  ##  ## Coefficients: ##                Estimate Std. Error t value Pr(>|t|)   ## (Intercept)     0.03165    0.05498   0.576   0.5829   ## density_factor -0.47197    0.13782  -3.424   0.0111 * ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## Residual standard error: 0.1648 on 7 degrees of freedom ## Multiple R-squared:  0.6262, Adjusted R-squared:  0.5728  ## F-statistic: 11.73 on 1 and 7 DF,  p-value: 0.01107 summary(r_model0b <- lm(I(recruit_1 - recruit_0) ~ treatment, data = recruits)) ##  ## Call: ## lm(formula = I(recruit_1 - recruit_0) ~ treatment, data = recruits) ##  ## Residuals: ##      Min       1Q   Median       3Q      Max  ## -0.20721 -0.07615 -0.02172  0.03025  0.32724  ##  ## Coefficients: ##                    Estimate Std. Error t value Pr(>|t|)   ## (Intercept)          0.2576     0.1048   2.459   0.0492 * ## treatmentcontrol    -0.2043     0.1482  -1.378   0.2173   ## treatmentincreased  -0.4548     0.1482  -3.069   0.0220 * ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## Residual standard error: 0.1815 on 6 degrees of freedom ## Multiple R-squared:  0.6117, Adjusted R-squared:  0.4823  ## F-statistic: 4.726 on 2 and 6 DF,  p-value: 0.05855 AIC(r_model0, r_model0b) ##           df       AIC ## r_model0   3 -3.170154 ## r_model0b  4 -0.827568"},{"path":"https://sebastianodebona.github.io/guppyDme/articles/DME-020_Density_dependence.html","id":"survival","dir":"Articles","previous_headings":"","what":"Survival","title":"Density dependence","text":"last trait can look Survival. can approximate survival calculating recapture rate individuals released. Now can analyse survival probability based density (including size sex). can adopt procedure , running model twice using density factor continuous value. Given difference AIC value larger 4, consider model density continuous value","code":"# first, we need a fresh and unmodified version of the cr_table cr <- readRDS(file.path(here::here(), \"vignettes\", \"DME_cr_data.rds\"))  # I also need to revise the treatment table so treatment \"E\" can be assigned to # a density factor value treatment_surv <- rbind(treatment_tab,                         treatment_tab %>%                            filter(treatment == \"I\") %>%                           mutate(treatment = \"E\")) %>%   ungroup() %>%   select(-patchID) %>%   rename(pool_density = density_factor)     # subsetting for individuals released after first capture # creating variable for recaptured or not released <- data %>%   filter(recap == 0, treatment %in% c(\"C\", \"D\", \"I\", \"E\"),          !isbabyMark, !isCohort) %>%   mutate(recaptured = as.numeric(markID %in% unique(cr$markID)),          SL_s = scale(as.numeric(SL)),          pool_treatment = plyr::mapvalues(treatment,                                           c(\"C\", \"D\", \"I\", \"E\"),                                           c(\"control\", \"decreased\", \"increased\", \"increased\")),          sex_stage = factor(sex_stage, levels = c(\"F\", \"I\", \"M\")))    # adding density as a continuous released %<>%   left_join(treatment_surv) %>%   mutate(pool_density = pool_density - 1) ## Joining with `by = join_by(streamID, treatment)` s0 <- glmer(recaptured ~ SL_s*sex_stage*pool_density + (1|streamID),            family = \"binomial\",            data = released) ## boundary (singular) fit: see help('isSingular') s1 <- glmer(recaptured ~ (SL_s+sex_stage+pool_density)^2 + (1|streamID),            family = \"binomial\",            data = released) ## boundary (singular) fit: see help('isSingular') s2 <- glmer(recaptured ~ SL_s*sex_stage+sex_stage*pool_density + (1|streamID),            family = \"binomial\",            data = released) ## boundary (singular) fit: see help('isSingular') summary(s2) ## Generalized linear mixed model fit by maximum likelihood (Laplace ##   Approximation) [glmerMod] ##  Family: binomial  ( logit ) ## Formula: recaptured ~ SL_s * sex_stage + sex_stage * pool_density + (1 |   ##     streamID) ##    Data: released ##  ##      AIC      BIC   logLik deviance df.resid  ##    780.3    824.4   -380.1    760.3      601  ##  ## Scaled residuals:  ##     Min      1Q  Median      3Q     Max  ## -2.4054 -1.0387  0.5613  0.7675  2.9081  ##  ## Random effects: ##  Groups   Name        Variance Std.Dev. ##  streamID (Intercept) 0        0        ## Number of obs: 611, groups:  streamID, 3 ##  ## Fixed effects: ##                         Estimate Std. Error z value Pr(>|z|)     ## (Intercept)               1.0742     0.1616   6.649 2.96e-11 *** ## SL_s                     -0.3082     0.1256  -2.454  0.01414 *   ## sex_stageI               -0.9292     0.3788  -2.453  0.01418 *   ## sex_stageM               -2.5317     0.3922  -6.455 1.08e-10 *** ## pool_density             -1.2130     0.3860  -3.143  0.00167 **  ## SL_s:sex_stageI          -0.1030     0.3471  -0.297  0.76664     ## SL_s:sex_stageM          -1.3844     0.6474  -2.138  0.03249 *   ## sex_stageI:pool_density   0.7549     0.6378   1.184  0.23661     ## sex_stageM:pool_density   2.2887     0.7321   3.126  0.00177 **  ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## Correlation of Fixed Effects: ##             (Intr) SL_s   sx_stI sx_stM pl_dns SL_:_I SL_:_M sx_I:_ ## SL_s        -0.543                                                  ## sex_stageI  -0.426  0.232                                           ## sex_stageM  -0.412  0.224  0.176                                    ## pool_densty -0.500  0.169  0.213  0.206                             ## SL_s:sx_stI  0.197 -0.362  0.639 -0.081 -0.061                      ## SL_s:sx_stM  0.105 -0.194 -0.045  0.624 -0.033  0.070               ## sx_stgI:pl_  0.302 -0.102 -0.327 -0.125 -0.605 -0.075  0.020        ## sx_stgM:pl_  0.264 -0.089 -0.112 -0.419 -0.527  0.032 -0.023  0.319 ## optimizer (Nelder_Mead) convergence code: 0 (OK) ## boundary (singular) fit: see help('isSingular') # LRT anova(s1, s0, test = \"Chisq\") ## Data: released ## Models: ## s1: recaptured ~ (SL_s + sex_stage + pool_density)^2 + (1 | streamID) ## s0: recaptured ~ SL_s * sex_stage * pool_density + (1 | streamID) ##    npar    AIC    BIC  logLik deviance  Chisq Df Pr(>Chisq) ## s1   11 781.23 829.80 -379.62   759.23                      ## s0   13 781.94 839.33 -377.97   755.94 3.2959  2     0.1924 s0b <-  glmer(recaptured ~ SL_s*sex_stage+sex_stage*pool_treatment + (1|location),            family = \"binomial\",            data = released) summary(s0b) ## Generalized linear mixed model fit by maximum likelihood (Laplace ##   Approximation) [glmerMod] ##  Family: binomial  ( logit ) ## Formula: recaptured ~ SL_s * sex_stage + sex_stage * pool_treatment +   ##     (1 | location) ##    Data: released ##  ##      AIC      BIC   logLik deviance df.resid  ##    782.9    840.3   -378.4    756.9      598  ##  ## Scaled residuals:  ##     Min      1Q  Median      3Q     Max  ## -2.2323 -0.9932  0.5428  0.7612  3.1104  ##  ## Random effects: ##  Groups   Name        Variance Std.Dev. ##  location (Intercept) 0.01717  0.131    ## Number of obs: 611, groups:  location, 12 ##  ## Fixed effects: ##                                    Estimate Std. Error z value Pr(>|z|)     ## (Intercept)                         1.22151    0.22233   5.494 3.93e-08 *** ## SL_s                               -0.29292    0.12666  -2.313  0.02074 *   ## sex_stageI                         -0.85998    0.48240  -1.783  0.07463 .   ## sex_stageM                         -2.84080    0.51683  -5.497 3.87e-08 *** ## pool_treatmentdecreased             0.22732    0.43536   0.522  0.60157     ## pool_treatmentincreased            -0.75777    0.27676  -2.738  0.00618 **  ## SL_s:sex_stageI                    -0.03964    0.35788  -0.111  0.91180     ## SL_s:sex_stageM                    -1.42080    0.65921  -2.155  0.03114 *   ## sex_stageI:pool_treatmentdecreased -0.15972    0.66142  -0.241  0.80919     ## sex_stageM:pool_treatmentdecreased -0.63987    0.86628  -0.739  0.46012     ## sex_stageI:pool_treatmentincreased  0.34335    0.46348   0.741  0.45881     ## sex_stageM:pool_treatmentincreased  1.43144    0.51876   2.759  0.00579 **  ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## Correlation of Fixed Effects: ##                    (Intr) SL_s   sx_stI sx_stM pl_trtmntd pl_trtmntn SL_:_I ## SL_s               -0.348                                                   ## sex_stageI         -0.399  0.157                                            ## sex_stageM         -0.372  0.145  0.174                                     ## pl_trtmntdc        -0.391 -0.159  0.152  0.143                              ## pl_trtmntnc        -0.726  0.046  0.282  0.262  0.351                       ## SL_s:sx_stI         0.124 -0.352  0.609 -0.049  0.057     -0.020            ## SL_s:sx_stM         0.071 -0.194 -0.027  0.536  0.032     -0.019      0.073 ## sx_stgI:pl_trtmntd  0.216  0.109 -0.337 -0.093 -0.617     -0.199     -0.052 ## sx_stgM:pl_trtmntd  0.165  0.083 -0.075 -0.389 -0.471     -0.152     -0.028 ## sx_stgI:pl_trtmntn  0.379 -0.028 -0.645 -0.154 -0.181     -0.518     -0.188 ## sx_stgM:pl_trtmntn  0.325 -0.018 -0.153 -0.707 -0.162     -0.443      0.006 ##                    SL_:_M sx_stgI:pl_trtmntd sx_stgM:pl_trtmntd ## SL_s                                                            ## sex_stageI                                                      ## sex_stageM                                                      ## pl_trtmntdc                                                     ## pl_trtmntnc                                                     ## SL_s:sx_stI                                                     ## SL_s:sx_stM                                                     ## sx_stgI:pl_trtmntd -0.020                                       ## sx_stgM:pl_trtmntd -0.041  0.312                                ## sx_stgI:pl_trtmntn  0.019  0.359              0.092             ## sx_stgM:pl_trtmntn -0.097  0.107              0.386             ##                    sx_stgI:pl_trtmntn ## SL_s                                  ## sex_stageI                            ## sex_stageM                            ## pl_trtmntdc                           ## pl_trtmntnc                           ## SL_s:sx_stI                           ## SL_s:sx_stM                           ## sx_stgI:pl_trtmntd                    ## sx_stgM:pl_trtmntd                    ## sx_stgI:pl_trtmntn                    ## sx_stgM:pl_trtmntn  0.263 AIC(s0, s0b) ##     df      AIC ## s0  13 781.9368 ## s0b 13 782.8971 # plotting mean_s <- released %>%   group_by(streamID, pool_treatment, pool_density, sex_stage) %>%   summarise(survival = mean(recaptured),             n = n(),             survival_SE = sqrt((survival*(1-survival))/n)) %>%   arrange(streamID, pool_density) %>%   mutate(\"stream\" = plyr::mapvalues(streamID,                                         c(\"CL1\", \"CL2\", \"TL\"),                                         c(\"Caigual 1\", \"Caigual 2\", \"Taylor\")),          sex = plyr::mapvalues(sex_stage,                                c(\"F\", \"I\", \"M\"),                                c(\"females\", \"immature\", \"males\")),          upperCI = survival + survival_SE,          lowerCI = survival - survival_SE,          upperCI = ifelse(upperCI > 1, 1, upperCI),          lowerCI = ifelse(lowerCI < 0 , 0, lowerCI)) ## `summarise()` has grouped output by 'streamID', 'pool_treatment', ## 'pool_density'. You can override using the `.groups` argument. p <- ggplot(mean_s, aes(x = pool_density, y = survival,                          group = stream, color = stream)) +   geom_point(aes(shape = stream), size = 3,                 position = position_dodge(0.02)) +   geom_path(aes(linetype = stream)) +   geom_errorbar(aes(x = pool_density,                      ymin = lowerCI,                      ymax = upperCI),                 width = 0.0,                 position = position_dodge(0.02)) +   scale_shape_manual(values = c(16,17,15)) +   scale_x_continuous(breaks = c(-0.5, 0, 0.5)) +   scale_color_manual(values=c(\"#DAA323\", \"#691E92\", \"#199958\")) +   labs(x = \"Proportional change in density\", y = \"Survival (± SE)\",        shape = \"Stream\", color = \"Stream\", linetype = \"Stream\") +    ylim(0,1) +   facet_grid(~ sex) +   theme_bw() p jpeg(file.path(here::here(), \"vignettes\", \"figures\", \"pool_level_survival.jpeg\"),      width = 8, height = 5, units = \"in\", res = 400) p dev.off() ## agg_png  ##       2"},{"path":"https://sebastianodebona.github.io/guppyDme/articles/DME-030_Habitat_use.html","id":"overview-and-setup","dir":"Articles","previous_headings":"","what":"Overview and Setup","title":"Habitat use","text":"use benthic area calculated create predictive models assign individual different habitats (associated probabilities) based size, sex habitat availability. fit Discrete Choice Model capture data alone calculate parameters defining probability choose habitat type based size sex, weighed habitat avilability. model fitted using package mlogit. Discrete Choice Models used econometrics analyse, describe predict individual choices among finite set discrete alternatives, based series covariates can attributes individual alternatives. example, can analyse predict preferred mean transport individual, based age income (individual attributes), train, bus car associated certain cost, travel time comfort (alternative attributes). Moreover, can include third category covariates. choice can repeated several times, time season weather might different (choice situation attributes) affect decision. use parameters estimated model calculate simulated habitat occupancy pool recapture, based individuals recaptured, size sex. Comparing simulated occupancy real occupancy detect effect density manipulation habitat use.","code":"# loading required packages library(tidyverse) ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ── ## ✔ dplyr     1.1.4     ✔ readr     2.1.5 ## ✔ forcats   1.0.0     ✔ stringr   1.5.1 ## ✔ ggplot2   3.5.1     ✔ tibble    3.2.1 ## ✔ lubridate 1.9.3     ✔ tidyr     1.3.1 ## ✔ purrr     1.0.2      ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag()    masks stats::lag() ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors library(magrittr) ##  ## Attaching package: 'magrittr' ##  ## The following object is masked from 'package:purrr': ##  ##     set_names ##  ## The following object is masked from 'package:tidyr': ##  ##     extract library(nnet) library(mlogit) ## Loading required package: dfidx ##  ## Attaching package: 'dfidx' ##  ## The following object is masked from 'package:stats': ##  ##     filter library(ggpubr)  # this package requires the package guppyDme to be installed. If the user wishes not to install the package, please comment out the \"library(guppyDme)\" line and run instead the lines commented out below  #### If you have the guppyDme package installed # loading package library(guppyDme)  # # If you do NOT wish to install the guppyDme package, please uncomment and run the following two lines of code, adding the package functions to the Global Environment and loading the data # source(file.path(here::here(), \"R\", \"package_functions.R\")) # load(file.path(here::here(), \"data\", \"DMEdata.rda\"))  # loading data data <- DMEdata pool_comp <- readRDS(file.path(here::here(), \"vignettes\", \"DME_pool_composition.rds\")) treatment_tab <- readRDS(file.path(here::here(), \"vignettes\", \"DME_density_factor_in_treatments.rds\"))  # I am creating an additional column in the dataset, redefining sex_stage classes data %<>%   mutate(sex_stage = score_sexst(., f_threshold = 14, f_unit = \"SL\")) ## Warning: There were 2 warnings in `mutate()`. ## The first warning was: ## ℹ In argument: `sex_stage = score_sexst(., f_threshold = 14, f_unit = \"SL\")`. ## Caused by warning in `ifelse()`: ## ! NAs introduced by coercion ## ℹ Run `dplyr::last_dplyr_warnings()` to see the 1 remaining warning."},{"path":"https://sebastianodebona.github.io/guppyDme/articles/DME-030_Habitat_use.html","id":"data-management","dir":"Articles","previous_headings":"","what":"Data management","title":"Habitat use","text":"determine structure data analysed using approach detailed vignette. proceeding, DCMs allow fit three separate kind covariate, defined scale vary: individual-specific covariates () alternative-specific covariates () choice situation specific covariates (C). case include size (), sex () benthic area associated habitat (). also variables including, might, future: : condition : mean variance water velocity, mean variance depth, represented substrate C: density, size structure, total benthic area, n. alternatives now ’ll just stick simplest model, fitted capture data . using relative benthic area measures different habitats. need transform data fit long format described . allows choice set vary choice events (meaning allow us remove set alternatives habitats present given pool).","code":"# adding pool composition information to the data data <- pool_comp %>%   mutate(recap = ifelse(cap_recap == \"cap\", 0, 1)) %>%   select(recap, streamID, patchID,          A = relA, B = relB, C = relC, D = relD, E = relE, tot_ba = tot) %>%   left_join(data, .) ## Adding missing grouping variables: `cap_recap` ## Joining with `by = join_by(streamID, recap, patchID)` # trimming only the needed data # We are here only including first capture, excluding Taylor mouth, and those datapoints where # habitat is not defined # We are also adding a unique ID column, to cope with repeated cohort marks later hab_sel <- data %>%   filter(recap == 0, streamID != \"TM\", !is.na(habitat)) %>%   select(markID, SL, sex_stage, habitat,          A, B, C, D, E) %>%   add_column(id = 1:nrow(.)) head(hab_sel) ## # A tibble: 6 × 10 ##   markID SL    sex_stage habitat     A     B     C     D     E    id ##   <fct>  <chr> <chr>     <fct>   <dbl> <dbl> <dbl> <dbl> <dbl> <int> ## 1 5B6O   21.29 F         D       0.159 0.279 0.434 0.129     0     1 ## 2 6W7K   20.62 F         D       0.159 0.279 0.434 0.129     0     2 ## 3 6G7K   17.38 F         D       0.159 0.279 0.434 0.129     0     3 ## 4 4G8K   17.64 M         D       0.159 0.279 0.434 0.129     0     4 ## 5 4P6P   19.01 F         D       0.159 0.279 0.434 0.129     0     5 ## 6 3R4K   15.72 F         D       0.159 0.279 0.434 0.129     0     6 # reshaping it as a long format hab_sel %<>%   gather(A, B, C, D, E, key = \"alt\", value = \"ba\") %>%   # just to better visualise it...   arrange(id) %>%   # creating the choice column   mutate(choice = as.numeric(habitat == alt)) %>%   select(id, markID, alt, choice, SL, sex_stage, ba) %>%   filter(ba > 0)  head(hab_sel) ## # A tibble: 6 × 7 ##      id markID alt   choice SL    sex_stage    ba ##   <int> <fct>  <chr>  <dbl> <chr> <chr>     <dbl> ## 1     1 5B6O   A          0 21.29 F         0.159 ## 2     1 5B6O   B          0 21.29 F         0.279 ## 3     1 5B6O   C          0 21.29 F         0.434 ## 4     1 5B6O   D          1 21.29 F         0.129 ## 5     2 6W7K   A          0 20.62 F         0.159 ## 6     2 6W7K   B          0 20.62 F         0.279 # We need to make sure that every individuals has a decision assigned. # If an individual was found in a habitat that is scored as having benthic area (ba) = 0, # such instance would be a mistake, and should be fixed. N_ROWS <- hab_sel %>%   group_by(id, markID) %>%   summarise(didPick = sum(choice)==1) %>%   filter(!didPick) %>%   nrow() ## `summarise()` has grouped output by 'id'. You can override using the `.groups` ## argument. stopifnot(N_ROWS == 0) # all looks good!"},{"path":"https://sebastianodebona.github.io/guppyDme/articles/DME-030_Habitat_use.html","id":"building-the-predictive-model","dir":"Articles","previous_headings":"","what":"Building the predictive model","title":"Habitat use","text":"build model, using guidelines two separate vignettes: vignette 1 | vignette 2. One individual covariates want include size. moment, individuals 10 mm assigned character string \"<10\". can dealt two ways. Either numeric value assigned, can random value drawn uniform distribution 8 10 mm (fixed value) removed analyses (analysed separately), large sized individuals. try approaches see different results .","code":""},{"path":"https://sebastianodebona.github.io/guppyDme/articles/DME-030_Habitat_use.html","id":"joint-sizes","dir":"Articles","previous_headings":"Building the predictive model","what":"Joint sizes","title":"Habitat use","text":", assign set value (9 mm) fish whose size 10 mm. can use function mlogit.data() transform data appropriate format. model work tibbles, since requires rownames. now need work data.frames instead tibbles. can now run model, making sure use right formula. interpretation sign estimate choice-specific variables (SL sex_stage) non-intuitive, since refers estimate compared levels. can interpreted estimated coefficient alternative-specific variables (ba) interesting effect seem habitats. occupied significantly different probabilities females, significant differences females two classes (trend safe occupancy C habitat immature individuals). Size also seems significant effect habitat occupancy. Benthic area also significant positive effect (can interpreted, given ’s alternative specific). ’s good keep mind reference level Intercept . intercept refers females (F) size 0. reference level dependent variable habitat . odd-ratios intercept refer odd ratio probability given habitat probability . function fitted() makes extremely easy calculate predicted probabilities, row data, habitats, given model parameters. ’s encouraging see predicted probability occupy “E”, available, zero. Generating mock dataset ’s possible display average probabilities occupy different habitats based size sex. mock dataset similar real data format. First, creating changing variables. Now individual repeated many times available habitats, habitats assigned alternative-specific variable, . case, relative benthic area. , make interpretation figures easier, assume habitats present equal proportions (0.20). Now need predict… …can plot. plotting, ’ll make sure trim predictions measured values size sex_stages, won’t infer non-realistic probabilities.","code":"# here I define the set value set_val <- 9  # all individuals below 10 mm (either measured or with a label \"<10\") # will be assigned the set value dj <- hab_sel %>%   mutate(SL = replace(SL, SL == \"<10\", set_val),          SL = as.numeric(SL),          SL = replace(SL, SL < 10, set_val)) mld_dj <- mlogit.data(as.data.frame(dj),                        shape = \"long\",                        alt.var = \"alt\",                        chid.var = \"id\") DCM_j <- mlogit(choice ~ ba | SL * sex_stage, mld_dj, reflevel = \"A\") summary(DCM_j) ##  ## Call: ## mlogit(formula = choice ~ ba | SL * sex_stage, data = mld_dj,  ##     reflevel = \"A\", method = \"nr\") ##  ## Frequencies of alternatives:choice ##        A        B        C        D        E  ## 0.127700 0.169953 0.434742 0.218779 0.048826  ##  ## nr method ## 6 iterations, 0h:0m:0s  ## g'(-H)^-1g = 2.74E-07  ## gradient close to zero  ##  ## Coefficients : ##                Estimate Std. Error z-value  Pr(>|z|)     ## (Intercept):B  3.041746   1.046394  2.9069 0.0036505 **  ## (Intercept):C  2.522669   0.787098  3.2050 0.0013505 **  ## (Intercept):D  6.613799   1.910017  3.4627 0.0005348 *** ## (Intercept):E  6.653669   1.710734  3.8894 0.0001005 *** ## ba             2.344074   0.307263  7.6289 2.376e-14 *** ## SL:B          -0.161337   0.048576 -3.3213 0.0008959 *** ## SL:C          -0.096595   0.035123 -2.7502 0.0059555 **  ## SL:D          -0.393126   0.103678 -3.7918 0.0001496 *** ## SL:E          -0.368928   0.088777 -4.1557 3.244e-05 *** ## sex_stageI:B   3.751584   1.502302  2.4972 0.0125170 *   ## sex_stageI:C   2.686685   1.279408  2.0999 0.0357339 *   ## sex_stageI:D   4.555692   2.225219  2.0473 0.0406286 *   ## sex_stageI:E  -2.368749   2.138873 -1.1075 0.2680884     ## sex_stageM:B   2.377612   4.114288  0.5779 0.5633374     ## sex_stageM:C  -0.580063   3.577356 -0.1621 0.8711889     ## sex_stageM:D  12.206176   7.618334  1.6022 0.1091090     ## sex_stageM:E  -2.615696   8.124831 -0.3219 0.7474993     ## SL:B          -0.247052   0.091056 -2.7132 0.0066640 **  ## SL:C          -0.155226   0.076621 -2.0259 0.0427754 *   ## SL:D          -0.321752   0.134643 -2.3897 0.0168637 *   ## SL:E           0.097280   0.128986  0.7542 0.4507336     ## SL:B          -0.132702   0.231284 -0.5738 0.5661292     ## SL:C           0.040154   0.199876  0.2009 0.8407801     ## SL:D          -0.740907   0.457738 -1.6186 0.1055276     ## SL:E           0.080319   0.470366  0.1708 0.8644133     ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## Log-Likelihood: -1099.5 ## McFadden R^2:  0.26578  ## Likelihood ratio test : chisq = 795.98 (p.value = < 2.22e-16) pp <- fitted(DCM_j, \"probabilities\") head(pp) ##           A         B         C          D E ## 1 0.1963599 0.1757113 0.5962863 0.03164248 0 ## 2 0.1836065 0.1830545 0.5948358 0.03850318 0 ## 3 0.1272047 0.2139024 0.5635508 0.09534219 0 ## 4 0.1270676 0.2125648 0.6241061 0.03626144 0 ## 5 0.1545004 0.1997245 0.5847627 0.06101233 0 ## 6 0.1016444 0.2234131 0.5286300 0.14631251 0 head(mld_dj) ## ~~~~~~~ ##  first 10 observations out of 4366  ## ~~~~~~~ ##    id markID alt choice    SL sex_stage        ba idx ## 1   1   5B6O   A      0 21.29         F 0.1585938 1:A ## 2   1   5B6O   B      0 21.29         F 0.2789063 1:B ## 3   1   5B6O   C      0 21.29         F 0.4335938 1:C ## 4   1   5B6O   D      1 21.29         F 0.1289062 1:D ## 5   2   6W7K   A      0 20.62         F 0.1585938 2:A ## 6   2   6W7K   B      0 20.62         F 0.2789063 2:B ## 7   2   6W7K   C      0 20.62         F 0.4335938 2:C ## 8   2   6W7K   D      1 20.62         F 0.1289062 2:D ## 9   3   6G7K   A      0 17.38         F 0.1585938 3:A ## 10  3   6G7K   B      0 17.38         F 0.2789063 3:B ##  ## ~~~ indexes ~~~~ ##    chid alt ## 1     1   A ## 2     1   B ## 3     1   C ## 4     1   D ## 5     2   A ## 6     2   B ## 7     2   C ## 8     2   D ## 9     3   A ## 10    3   B ## indexes:  1, 2 # vector of lengths sls <- seq(range(mld_dj$SL, na.rm = T)[1], range(mld_dj$SL, na.rm = T)[2], length.out = 50) # vector of sex_stages sxs <- unique(mld_dj$sex_stage, na.rm = T)  # then using expand.grid I can create all combinations.  # Each of them is a hypothetical individual, so it whould receive an id block <- cbind(expand.grid(SL = sls, sex_stage = sxs),                 id = 1:(length(sls)*length(sxs))) habs <- data.frame(alt = unique(as.character(mld_dj$alt),                                  na.rm = T),                    ba = .2)  # now I can \"expand grid\" again (this time using merge, since I am combining dataframes) mock_d <- merge(habs, block, by = NULL)  # habitat alternatives should be turned into factors mock_d$alt <- as.factor(mock_d$alt) # generating predictions and storing them side by side with the block # (which unlike mock_d does not have repeated individuals once per habitat) pred_mock <- cbind(block,                    predict(DCM_j, newdata = mock_d, type = \"probs\")                    )              # I don't want to show prediction for irrational values (e.g. very # large immature individuals, which are not present, or very small mature ones) # I'll limit the plotting to reasonable values # here I'll find the ranges for female, males and immature individuals low_m <- min(as.numeric(data %>% filter(sex_stage == \"M\") %>% pull(SL)), na.rm = T) ## Warning: NAs introduced by coercion low_f <- min(as.numeric(data %>% filter(sex_stage == \"F\") %>% pull(SL)), na.rm = T) hi_m <- max(as.numeric(data %>% filter(sex_stage == \"M\") %>% pull(SL)), na.rm = T) ## Warning: NAs introduced by coercion hi_i <- max(as.numeric(data %>% filter(sex_stage == \"I\") %>% pull(SL)), na.rm = T) ## Warning: NAs introduced by coercion pred_mock %<>%   filter(sex_stage == \"I\" & SL < hi_i |            sex_stage == \"F\" & SL > low_f |            sex_stage == \"M\" & SL > low_m & SL < hi_m)        # reshaping dataset to long(er) format, and releveling sex_stage pred_mock %<>%   gather(A, B, C, D, E, key = habitat, value = probability) %>%   mutate(sex_stage = factor(sex_stage, levels = c(\"I\", \"M\", \"F\"))) # plotting ggplot(pred_mock, aes(x = SL, y = probability, colour = sex_stage)) +   geom_line() +   ylim(0,1) +   scale_color_manual(values = c(\"#1E88E5\", \"#FFC107\", \"#004D40\")) +   facet_grid(habitat ~ ., scales = \"free\", labeller = labeller(habitat = hablab())) +   ggtitle(\"Joint size model - predictions\")"},{"path":"https://sebastianodebona.github.io/guppyDme/articles/DME-030_Habitat_use.html","id":"split-sizes","dir":"Articles","previous_headings":"Building the predictive model","what":"Split sizes","title":"Habitat use","text":"now repeat analyses, using split size approach. run model individuals larger 10 mm, model (size-independent) individuals threshold value. working two datasets. First, adults regressions. results adults similar obtained individuals “Joint size” model. can now repeat analyses, individuals < 10 mm. combined plot split sizes.","code":"# for now I will only take individuals with a numeric size # creating a dataset for adults (> 10mm, with size information) ds_ads <- hab_sel %>%   mutate(SL = as.numeric(SL)) %>%   filter(SL > 10) ## Warning: There was 1 warning in `mutate()`. ## ℹ In argument: `SL = as.numeric(SL)`. ## Caused by warning: ## ! NAs introduced by coercion # and a dataset for babies, <10mm, and without precise SL measurements ds_bbs <- hab_sel %>%   filter(SL == \"<10\" | as.numeric(SL)<10) ## Warning: There was 1 warning in `filter()`. ## ℹ In argument: `SL == \"<10\" | as.numeric(SL) < 10`. ## Caused by warning: ## ! NAs introduced by coercion # converting dataset into mlogit format mld_ads <- mlogit.data(as.data.frame(ds_ads),                         shape = \"long\",                        alt.var = \"alt\",                        chid.var = \"id\")  # running model DCM_ads <- mlogit(choice ~ ba | SL * sex_stage, mld_ads, reflevel = \"A\")  # visualizing results summary(DCM_ads) ##  ## Call: ## mlogit(formula = choice ~ ba | SL * sex_stage, data = mld_ads,  ##     reflevel = \"A\", method = \"nr\") ##  ## Frequencies of alternatives:choice ##        A        B        C        D        E  ## 0.173971 0.163347 0.501992 0.104914 0.055777  ##  ## nr method ## 6 iterations, 0h:0m:0s  ## g'(-H)^-1g = 0.000139  ## successive function values within tolerance limits  ##  ## Coefficients : ##                 Estimate Std. Error z-value  Pr(>|z|)     ## (Intercept):B  2.9255178  1.0463262  2.7960 0.0051741 **  ## (Intercept):C  2.5015990  0.7795960  3.2088 0.0013327 **  ## (Intercept):D  6.5548691  1.9087396  3.4341 0.0005944 *** ## (Intercept):E  6.7215712  1.7023475  3.9484 7.867e-05 *** ## ba             1.8224748  0.3457420  5.2712 1.355e-07 *** ## SL:B          -0.1572519  0.0485833 -3.2367 0.0012090 **  ## SL:C          -0.0922041  0.0348057 -2.6491 0.0080704 **  ## SL:D          -0.3914744  0.1036319 -3.7775 0.0001584 *** ## SL:E          -0.3694206  0.0883616 -4.1808 2.905e-05 *** ## sex_stageI:B   6.2723055  2.1447820  2.9244 0.0034507 **  ## sex_stageI:C   4.6461756  1.8366831  2.5297 0.0114175 *   ## sex_stageI:D   6.3184530  2.8229254  2.2383 0.0252038 *   ## sex_stageI:E  -0.6554867  2.7615549 -0.2374 0.8123764     ## sex_stageM:B   2.9088381  4.0900103  0.7112 0.4769569     ## sex_stageM:C  -0.0832127  3.5448107 -0.0235 0.9812718     ## sex_stageM:D  12.8493884  7.5828446  1.6945 0.0901638 .   ## sex_stageM:E  -2.0030492  8.1144747 -0.2468 0.8050252     ## SL:B          -0.4026189  0.1321971 -3.0456 0.0023222 **  ## SL:C          -0.2718278  0.1090607 -2.4924 0.0126867 *   ## SL:D          -0.4238873  0.1774203 -2.3892 0.0168865 *   ## SL:E          -0.0056157  0.1694523 -0.0331 0.9735627     ## SL:B          -0.1628600  0.2298388 -0.7086 0.4785829     ## SL:C           0.0115024  0.1979583  0.0581 0.9536647     ## SL:D          -0.7793494  0.4555359 -1.7108 0.0871105 .   ## SL:E           0.0432260  0.4697855  0.0920 0.9266884     ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## Log-Likelihood: -829.03 ## McFadden R^2:  0.18065  ## Likelihood ratio test : chisq = 365.56 (p.value = < 2.22e-16) mld_bbs <- mlogit.data(as.data.frame(ds_bbs),                        shape = \"long\",                         alt.var = \"alt\",                         chid.var = \"id\")  # running model DCM_bbs <-  mlogit(choice ~ ba | 1, mld_bbs, reflevel = \"A\") # visualizing results summary(DCM_bbs) ##  ## Call: ## mlogit(formula = choice ~ ba | 1, data = mld_bbs, reflevel = \"A\",  ##     method = \"nr\") ##  ## Frequencies of alternatives:choice ##        A        B        C        D        E  ## 0.016026 0.185897 0.272436 0.493590 0.032051  ##  ## nr method ## 6 iterations, 0h:0m:0s  ## g'(-H)^-1g = 1.44E-07  ## gradient close to zero  ##  ## Coefficients : ##               Estimate Std. Error z-value  Pr(>|z|)     ## (Intercept):B  2.65913    0.47181  5.6360 1.741e-08 *** ## (Intercept):C  2.10509    0.47361  4.4448 8.797e-06 *** ## (Intercept):D  4.39983    0.47246  9.3126 < 2.2e-16 *** ## (Intercept):E  1.33148    0.55660  2.3922   0.01675 *   ## ba             4.50326    0.74174  6.0712 1.270e-09 *** ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## Log-Likelihood: -262.95 ## McFadden R^2:  0.293  ## Likelihood ratio test : chisq = 217.94 (p.value = < 2.22e-16) # predictions for adults sls_ads <- seq(range(mld_ads$SL, na.rm = T)[1], range(mld_ads$SL, na.rm = T)[2], length.out = 50) sxs_ads <- unique(mld_ads$sex_stage, na.rm = T) block_ads <- cbind(expand.grid(SL = sls_ads, sex_stage = sxs_ads),                 id = 1:(length(sls_ads)*length(sxs_ads))) habs_ads <- data.frame(alt = unique(as.character(mld_ads$alt), na.rm = T),               ba = .2) mock_ads <- merge(habs_ads, block, by = NULL)  # predictions for adults pred_mock_s <- cbind(block_ads,                    predict(DCM_ads, newdata = mock_ads, type = \"probs\")                    )  # as done for the joint model, triming sex_stage to actual size range pred_mock_s %<>%   filter(sex_stage == \"I\" & SL < hi_i |            sex_stage == \"F\" & SL > low_f |            sex_stage == \"M\" & SL > low_m & SL < hi_m)  # reshaping dataset pred_mock_s %<>%   gather(A, B, C, D, E, key = habitat, value = probability)   # creating a separate predictions for babies and combining the two datasets pred_mock_s <- merge(data.frame(probability = predict(DCM_bbs,                                                       newdata = habs,                                                       type = \"probs\"),                                 habitat = names(predict(DCM_bbs,                                                       newdata = habs,                                                       type = \"probs\"))),                       data.frame(SL = c(8, 10), sex_stage = rep(\"< 10mm\", 2))) %>%   bind_rows(pred_mock_s)  # reordering factors for sex_stage pred_mock_s %<>%   mutate(sex_stage = factor(sex_stage, levels = c(\"< 10mm\", \"I\", \"M\", \"F\")))  # plotting ggplot(pred_mock_s, aes(x = SL, y = probability, colour = sex_stage)) +   geom_line() +   ylim(0,1) +   scale_color_manual(values = c(\"black\", \"#1E88E5\", \"#FFC107\", \"#004D40\")) +   facet_grid(habitat ~ ., scales = \"free\", labeller = labeller(habitat = hablab())) +   ggtitle(\"Split-size Model\")"},{"path":"https://sebastianodebona.github.io/guppyDme/articles/DME-030_Habitat_use.html","id":"simulations-of-occupancy","dir":"Articles","previous_headings":"","what":"Simulations of Occupancy","title":"Habitat use","text":"Now generated models capture data can use , together census data recapture, generate predicted occupancy. density affected habitat use, predicted occupancy match observed one. , matching observation control pool, whereas observed occupancy increased decreased pool match predicted one. generate simulations, simplicity, use joint model since quite closely matches split one. First, extract data recapture. predict function mlogit turns rather clunky confusing. trying follow direction user “Manos C” thread make work. , adopt trick suggested user “Robert Bray”. can now extract predicted probabilities individual one habitats given pool, based size, sex habitat availability recapture.","code":"# I will here add information on the pool treatment, # filter out the capture event info and transform SL \"<10\" # values into the set_value recap_data <- treatment_tab %>%   mutate(pool_treatment = str_replace_all(treatment,                                           c(\"I\" = \"increased\",                                             \"C\" = \"control\",                                             \"D\" = \"decreased\"))) %>%   select(streamID, patchID, pool_treatment) %>%   ungroup() %>%   right_join(data %>% filter(recap == 1,                              !is.na(habitat))) %>%   mutate(SL = replace(SL, SL == \"<10\", set_val),          SL = as.numeric(SL),          SL = replace(SL, SL < 10, set_val)) %>%   filter(!is.na(pool_treatment), !is.na(sex_stage)) ## Joining with `by = join_by(streamID, patchID)` ## Warning: There was 1 warning in `mutate()`. ## ℹ In argument: `SL = as.numeric(SL)`. ## Caused by warning: ## ! NAs introduced by coercion # filtering out the NAs for sex_stage is extremely important. # see https://stats.stackexchange.com/questions/6702/predict-after-running-the-mlogit-function-in-r  # now I can select the columns I need for the predictions # I am keeping the habitat to generate a fake choice column later to_predict <- recap_data %>%   select(streamID, patchID, markID, SL, sex_stage, habitat, pool_treatment,          A, B, C, D, E) %>%   add_column(id = 1:nrow(.))  # extracting only individual info (dropping habitat area) block_predict <- to_predict %>%   select(streamID, patchID, markID, SL, sex_stage, habitat, pool_treatment)  # and finally reshape is as a long format # also, releveling the factors to match those above and creating mock choice ml_topred <- to_predict %>%   gather(A, B, C, D, E, key = \"alt\", value = \"ba\") %>%   arrange(id) %>%   mutate(alt = factor(alt, levels = levels(mock_d$alt)),          sex_stage = factor(sex_stage, levels = levels(mock_d$sex_stage)),          choice = ifelse(habitat == alt, 1, 0)) %>%   select(alt, ba, SL, sex_stage, choice, id) %>%   filter(ba > 0) %>%   mutate(chid = id) # the step of filtering out the choices where ba = 0 (non-existing # alternatives) is crucial since it allows to predict a probability # equal to zero to choose that habitat!  # I need to run the function `mlogit.data` (according to Manos C), # as if this data needed to be anlysed ml_topred <- mlogit.data(as.data.frame(ml_topred), shape = \"long\",                        alt.var = \"alt\", chid.var = \"id\") # before storing the model anywhere, I am making some quick tests # whether the predict works out well. # The number of predictions should be equal to the number of individuals stopifnot(nrow(block_predict) == nrow(predict(DCM_j, newdata = ml_topred, type = \"probs\")))  # also, the predict should be unaffected by the arbitrary choice I introduced x <- predict(DCM_j, newdata = ml_topred, type = \"probs\")[1,] ml_topred2 <- ml_topred ml_topred2[1:3, \"choice\"] <- c(1, 0, 0) y <- predict(DCM_j, newdata = ml_topred2, type = \"probs\")[1,]  stopifnot(sum(x-y) == 0) # all good, we can store the predictions  recap_preds <- cbind(block_predict,                       predict(DCM_j, newdata = ml_topred, type = \"probs\"))"},{"path":"https://sebastianodebona.github.io/guppyDme/articles/DME-030_Habitat_use.html","id":"comparing-simulations-to-observed-occupancy","dir":"Articles","previous_headings":"Simulations of Occupancy","what":"Comparing simulations to observed occupancy","title":"Habitat use","text":"Now generated predicted probabilities individual given habitat given size, sex habitat availability, can generate simulations occupancy pool compare reference value real observed occupancy. running simulation, can plot observed occupancy sum probabilities individuals habitat (summing individual probability distributions among habitats).  filled circles represent observed occupancy, empty diamonds represent predicted occupancy.","code":"# gathering predicted distributions pred_distr <- recap_preds %>%   group_by(streamID, pool_treatment) %>%   summarize(A = sum(A),             B = sum(B),             C = sum(C),             D = sum(D),             E = sum(E)) %>% gather(A, B, C, D, E, key = habitat, value = predicted) ## `summarise()` has grouped output by 'streamID'. You can override using the ## `.groups` argument. # now observed distributions obs_distr <- recap_preds %>%   group_by(streamID, pool_treatment) %>%   summarize(A = sum(habitat == \"A\"),             B = sum(habitat == \"B\"),             C = sum(habitat == \"C\"),             D = sum(habitat == \"D\"),             E = sum(habitat == \"E\")) %>% gather(A, B, C, D, E, key = habitat, value = observed) ## `summarise()` has grouped output by 'streamID'. You can override using the ## `.groups` argument. # now joining the two pred_v_obs <- inner_join(pred_distr, obs_distr) %>%   filter(observed > 0) ## Joining with `by = join_by(streamID, pool_treatment, habitat)` # and plotting ggplot(pred_v_obs, aes(x = habitat, col = habitat)) +   geom_point(aes(y = predicted), shape = 5) +   geom_point(aes(y = observed)) +   facet_grid(streamID ~ pool_treatment) +   scale_color_manual(values = c(   \"#ffd700\",   \"#fa8775\",   \"#cd34b5\",   \"#9d02d7\",   \"#0000ff\")) +   theme_bw()"},{"path":"https://sebastianodebona.github.io/guppyDme/articles/DME-035_DD_habitat_use.html","id":"overview-and-setup","dir":"Articles","previous_headings":"","what":"Overview and Setup","title":"Density-dependent habitat use","text":"vignette, build previous vignette, adopting Discrete-Choice model approach including density independent variable analyzing one go capture recapture data. previous vignette trying generate estimates based capture model, predict expected habitat occupancy recapture compare observed occupancy. clear, visible trend visible using approach, therefore, somwhat complicated d-c model includes density first place might shade light . analysing capture recapture time, create mismatch individuals choice situation. Now id chid defined separately, assign chid value corresponding 1 capture 2 recapture. ’s important, account correctly individuals analysed twice: individual recaptured, ’s id . density experienced choice situation specific covariate: density factor associated capture always 1 (since pools assumed equilibrium manipulated). analyses adopt joint model, considering close results split model (joint easier).","code":""},{"path":"https://sebastianodebona.github.io/guppyDme/articles/DME-035_DD_habitat_use.html","id":"required-packages-and-data","dir":"Articles","previous_headings":"","what":"Required packages and Data","title":"Density-dependent habitat use","text":"","code":"# loading required packages library(tidyverse) ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ── ## ✔ dplyr     1.1.4     ✔ readr     2.1.5 ## ✔ forcats   1.0.0     ✔ stringr   1.5.1 ## ✔ ggplot2   3.5.1     ✔ tibble    3.2.1 ## ✔ lubridate 1.9.3     ✔ tidyr     1.3.1 ## ✔ purrr     1.0.2      ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag()    masks stats::lag() ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors library(magrittr) ##  ## Attaching package: 'magrittr' ##  ## The following object is masked from 'package:purrr': ##  ##     set_names ##  ## The following object is masked from 'package:tidyr': ##  ##     extract library(nnet) library(mlogit) ## Loading required package: dfidx ##  ## Attaching package: 'dfidx' ##  ## The following object is masked from 'package:stats': ##  ##     filter library(ggpubr) library(rtf) ##  ## Attaching package: 'rtf' ##  ## The following object is masked from 'package:purrr': ##  ##     done ##  ## The following object is masked from 'package:tibble': ##  ##     view # this package requires the package guppyDme to be installed. If the user wishes not to install the package, please comment out the \"library(guppyDme)\" line and run instead the lines commented out below  #### If you have the guppyDme package installed # loading package library(guppyDme)  # # If you do NOT wish to install the guppyDme package, please uncomment and run the following two lines of code, adding the package functions to the Global Environment and loading the data # source(file.path(here::here(), \"R\", \"package_functions.R\")) # load(file.path(here::here(), \"data\", \"DMEdata.rda\"))  # loading data data <- DMEdata pool_comp <- readRDS(file.path(here::here(), \"vignettes\", \"DME_pool_composition.rds\")) treatment_tab <- readRDS(file.path(here::here(), \"vignettes\", \"DME_density_factor_in_treatments.rds\"))  # I am creating an additional column in the dataset, redefining sex_stage classes # I am also transforming SL into numeric, substituting the \"<10\", and  # every numeric value below 10mm, with a numeric `set_value`. set_value <- 9 data %<>%   mutate(SL = replace(SL, SL == \"<10\", set_value),          SL = as.numeric(SL),          SL = replace(SL, SL < 10, set_value),          sex_stage = score_sexst(., f_threshold = 14, f_unit = \"SL\"),          sex_stage = factor(sex_stage, levels = c(\"F\", \"I\", \"M\"))) ## Warning: There were 3 warnings in `mutate()`. ## The first warning was: ## ℹ In argument: `SL = as.numeric(SL)`. ## Caused by warning: ## ! NAs introduced by coercion ## ℹ Run `dplyr::last_dplyr_warnings()` to see the 2 remaining warnings."},{"path":"https://sebastianodebona.github.io/guppyDme/articles/DME-035_DD_habitat_use.html","id":"data-handling","dir":"Articles","previous_headings":"","what":"Data handling","title":"Density-dependent habitat use","text":"using, , vignette guide decision data handling model construction. , include pool composition info (relative benthic area habitat present) density information (1 every pool capture, corresponds modified density recap). dataset now contains lot information don’t need, can trim . need include variable individual id variable chid. , need careful id assigned cohort marks. simply use markID variable generate id, cohort marks considered repeated measures individual. Now transforming data long format, allow set alternative vary amonge choices (see ). can now transform data appropriate format function mlogit.data(), ready analysis.","code":"# adding pool composition info data <- pool_comp %>%   mutate(recap = ifelse(cap_recap == \"cap\", 0, 1)) %>%   select(recap, streamID, patchID,          A = relA, B = relB, C = relC, D = relD, E = relE, tot_ba = tot) %>%   left_join(data, .) ## Adding missing grouping variables: `cap_recap` ## Joining with `by = join_by(streamID, recap, patchID)` # adding density info data <- treatment_tab %>%   add_column(recap = 1) %>%   select(-treatment) %>%   rename(pool_density = density_factor) %>%   left_join(data,.) %>%   mutate(pool_density = ifelse(recap == 0, 1, pool_density)) ## Joining with `by = join_by(streamID, recap, patchID)` # trimming only the needed data # - excluding Taylor mouth # - excluding undefined habitat hdata <- data %>%   filter(streamID != \"TM\", !is.na(habitat)) %>%   select(markID, SL, sex_stage, habitat, pool_density, recap, isbabyMark, isCohort,          A, B, C, D, E)  # here I will extract all individuals who have more than 1 # record per cap/recap not_unique_ids <- as.data.frame(table(hdata$markID, hdata$recap)) %>%   filter(Freq > 1) %>%   pull(Var1) %>%   as.character()  # to assign unique ids, first I generate a column of actually unique ids # that are above the maximum number of unique markIDs # then, I can draw unique values from this column for individuals # that don't already have a unique id hdata %<>%   mutate(bench_id = (max(as.numeric(markID)) + 1):(max(as.numeric(markID)) + nrow(.)),          id = ifelse(!(markID %in% not_unique_ids), as.numeric(markID), bench_id)) %>%   arrange(id) %>%   mutate(chid = 1:nrow(.)) %>%   select(-bench_id) # reshaping it as a long format hdata %<>%   gather(A, B, C, D, E, key = \"alt\", value = \"ba\") %>%   mutate(choice = as.numeric(habitat == alt)) %>%   arrange(chid) %>%   select(id, chid, markID, alt, choice, SL, sex_stage, ba, pool_density, recap) %>%   filter(ba > 0) head(hdata) ## # A tibble: 6 × 10 ##      id  chid markID alt   choice    SL sex_stage    ba pool_density recap ##   <dbl> <int> <fct>  <chr>  <dbl> <dbl> <fct>     <dbl>        <dbl> <dbl> ## 1     2     1 105Y   A          0  23.4 F         0.428            1     0 ## 2     2     1 105Y   B          0  23.4 F         0.265            1     0 ## 3     2     1 105Y   C          1  23.4 F         0.162            1     0 ## 4     2     1 105Y   D          0  23.4 F         0.145            1     0 ## 5     3     2 1B     A          0  11.6 I         0.428            1     0 ## 6     3     2 1B     B          0  11.6 I         0.265            1     0 # re-centering pool_density, creating factorial treatment hdata %<>%   mutate(pool_density = pool_density - 1,          treatment = ifelse(pool_density == 0, \"control\",                             ifelse(pool_density > 0, \"increased\", \"decreased\")))  # I need to make sure that every individuals has a decision assigned. # In the case an individual was found in a habitat at ba 0, this would not be the case # of course, such instance would be a mistake, and should be fixed. n_rows <- hdata %>%   group_by(id, markID, chid) %>%   summarise(didPick = sum(choice)==1) %>%   filter(!didPick) %>%   nrow() ## `summarise()` has grouped output by 'id', 'markID'. You can override using the ## `.groups` argument. # check to see if any fish did not decide stopifnot(n_rows == 0) # all good data_mlogit <- mlogit.data(as.data.frame(hdata), shape = \"long\",                        alt.var = \"alt\", id.var = \"id\", chid.var = \"chid\")"},{"path":"https://sebastianodebona.github.io/guppyDme/articles/DME-035_DD_habitat_use.html","id":"analysis","dir":"Articles","previous_headings":"","what":"Analysis","title":"Density-dependent habitat use","text":"need careful specify formula. One package:mlogit’s vignettes pretty clear guide. formula split three parts separated symbol |., form three parts represent 3 different tipe variables: part correponds alternative-specific covariates generic coefficient (value consistent across alternatives, e.g. money always ) part II correponds choice-situation-specific covariates, change among choices apply alternatives choice part III correponds alternative-specific covariates alternative-specific coefficients (.e. time spent transport mattered differently: 10 minutes public transport fine, 10 minutes walking less preferable) analyses, part (benthic area ba) part II (standard length SL, sex sex_stage density pool_density). might try introduce also whether choice made capture recapture (recap), also fall part II. Let’s try run model. NOTE: contrast done , running model treatment factor model converge. number interactions likely little big. export output doc table. interpretation results somewhat tricky, plot estimated probabilities done previous vignette, time also including density values. now ready generate predictions plot .  quick thoughts ’s going : inflow (habitat “”) thought good quality habitat drift feeding. Drift feeding requires large enough mouths, expect large individuals benefit . can observe control increased density large females dominate habitat, decrease treatment habitat becomes accessible relatively large males immatures well. Large females seen abandon core swamp area occupy low density move predominantly inflow high density. can due shift diet, making use harder get probably easier monopolise drift feeding options, instead using highly demanded resources “everyone’s land” (core). Small juveniles tend occupy central habitats (core beach associated) low density, seem relegated marginal areas (swamp) density high. Swamps high density seem pretty secure habitat, large individuals often marginal.","code":"formula = response ~ part I | part II | part III dcmodel <- mlogit(choice ~ ba | SL * sex_stage * pool_density, data_mlogit, reflevel = \"A\") summary(dcmodel) ##  ## Call: ## mlogit(formula = choice ~ ba | SL * sex_stage * pool_density,  ##     data = data_mlogit, reflevel = \"A\", method = \"nr\") ##  ## Frequencies of alternatives:choice ##        A        B        C        D        E  ## 0.139325 0.142653 0.503566 0.148359 0.066096  ##  ## nr method ## 7 iterations, 0h:0m:1s  ## g'(-H)^-1g = 2.4E-06  ## successive function values within tolerance limits  ##  ## Coefficients : ##                   Estimate  Std. Error z-value  Pr(>|z|)     ## (Intercept):B    1.1674167   0.8991584  1.2983 0.1941692     ## (Intercept):C    2.3176553   0.5301321  4.3718 1.232e-05 *** ## (Intercept):D    5.3399777   1.6773118  3.1837 0.0014543 **  ## (Intercept):E    6.1904968   1.2523596  4.9431 7.690e-07 *** ## ba               2.5159554   0.2359196 10.6645 < 2.2e-16 *** ## SL:B            -0.1099154   0.0429682 -2.5581 0.0105257 *   ## SL:C            -0.0899314   0.0244970 -3.6711 0.0002415 *** ## SL:D            -0.3632761   0.0934348 -3.8880 0.0001011 *** ## SL:E            -0.3734266   0.0682696 -5.4699 4.503e-08 *** ## sex_stageI:B     6.4004604   1.1942450  5.3594 8.349e-08 *** ## sex_stageI:C     2.5702891   0.8800267  2.9207 0.0034925 **  ## sex_stageI:D     4.3141214   1.8716277  2.3050 0.0211660 *   ## sex_stageI:E    -2.5065488   1.5053299 -1.6651 0.0958896 .   ## sex_stageM:B    -0.2363717   3.5323526 -0.0669 0.9466484     ## sex_stageM:C    -1.1718102   2.4614838 -0.4761 0.6340327     ## sex_stageM:D     8.1603652   6.7204897  1.2143 0.2246517     ## sex_stageM:E     4.3636107   6.0600425  0.7201 0.4714864     ## pool_density:B   0.1782479   3.2920565  0.0541 0.9568198     ## pool_density:C   0.6107412   2.0200165  0.3023 0.7623893     ## pool_density:D   8.0267115   7.3670819  1.0895 0.2759170     ## pool_density:E  -1.1580577   7.5099624 -0.1542 0.8774498     ## SL:B            -0.3983090   0.0737992 -5.3972 6.769e-08 *** ## SL:C            -0.1499731   0.0548431 -2.7346 0.0062459 **  ## SL:D            -0.2915782   0.1145791 -2.5448 0.0109348 *   ## SL:E             0.1584038   0.0917967  1.7256 0.0844206 .   ## SL:B             0.0223629   0.2016629  0.1109 0.9117016     ## SL:C             0.0670554   0.1404813  0.4773 0.6331300     ## SL:D            -0.5057856   0.4088878 -1.2370 0.2160949     ## SL:E            -0.3051034   0.3631274 -0.8402 0.4007904     ## SL:B            -0.0408326   0.1588940 -0.2570 0.7971939     ## SL:C            -0.0642783   0.0940971 -0.6831 0.4945397     ## SL:D            -0.5774917   0.3861778 -1.4954 0.1348091     ## SL:E             0.0962236   0.4251557  0.2263 0.8209482     ## sex_stageI:B   -11.0498652   4.3096914 -2.5640 0.0103486 *   ## sex_stageI:C   -12.6920015   3.1995323 -3.9668 7.283e-05 *** ## sex_stageI:D   -15.7083906   8.3286594 -1.8861 0.0592862 .   ## sex_stageI:E    -4.2471880   8.6599864 -0.4904 0.6238239     ## sex_stageM:B     0.4481004  15.6214105  0.0287 0.9771158     ## sex_stageM:C    -0.2484898  10.7429269 -0.0231 0.9815461     ## sex_stageM:D   -29.4673109  26.3404714 -1.1187 0.2632645     ## sex_stageM:E     2.1251563  40.9060792  0.0520 0.9585669     ## SL:B             0.6843901   0.2755139  2.4840 0.0129898 *   ## SL:C             0.8220309   0.2079032  3.9539 7.688e-05 *** ## SL:D             1.1403822   0.5240143  2.1762 0.0295371 *   ## SL:E             0.3307430   0.5401152  0.6124 0.5403020     ## SL:B             0.0407358   0.8961742  0.0455 0.9637445     ## SL:C             0.0997719   0.6147788  0.1623 0.8710782     ## SL:D             1.9324551   1.5872610  1.2175 0.2234225     ## SL:E            -0.0097941   2.4021226 -0.0041 0.9967468     ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## Log-Likelihood: -2178.5 ## McFadden R^2:  0.23859  ## Likelihood ratio test : chisq = 1365.3 (p.value = < 2.22e-16) names(summary(dcmodel)) ##  [1] \"coefficients\"  \"logLik\"        \"gradient\"      \"hessian\"       ##  [5] \"est.stat\"      \"fitted.values\" \"probabilities\" \"linpred\"       ##  [9] \"indpar\"        \"residuals\"     \"omega\"         \"rpar\"          ## [13] \"nests\"         \"model\"         \"freq\"          \"formula\"       ## [17] \"call\"          \"CoefTable\"     \"lratio\"        \"mfR2\" ptable <- round(as.data.frame(summary(dcmodel)$CoefTable), 3) %>%   add_column(coeff = rownames(as.data.frame(summary(dcmodel)$CoefTable)), .before = 1)   rtffile <- RTF(file.path(here::here(), \"vignettes\", \"DCM_output.doc\"))  # this can be an .rtf or a .doc addTable(rtffile, ptable) done(rtffile) sls <- modelr::seq_range(hdata$SL, n= 50) sxs <- levels(hdata$sex_stage) ds <- c(-.5, 0, .5)  # then using expand grid I can create all combinations.  # Each of them is an hypothetical individual, so whould receive an id block <- cbind(expand.grid(SL = sls, sex_stage = sxs, pool_density = ds)) %>%   add_column(id = 1:nrow(.))  # I can now expand this block to include all possible alternatives # here, I am weighing them all the same habs <- data.frame(alt = unique(hdata$alt),                    ba = .2) mock_d <- merge(habs, block, by = NULL) # generating predictions and storing them side by side with the block # (which unlike mock_d does not have repeated individuals once per habitat) pred_mock <- cbind(block,                    predict(dcmodel, newdata = mock_d, type = \"probs\")                    )  # reshaping dataset to long(er) format, and releveling sex_stage pred_mock %<>%   gather(A, B, C, D, E, key = habitat, value = probability) %>%   mutate(sex_stage = factor(sex_stage, levels = c(\"I\", \"M\", \"F\")))  #### TRIMMING ##### COPY-PASTING this NOW, REPLACE WITH NEW in_range FUNCTION! low_m <- min(as.numeric(data %>% filter(sex_stage == \"M\") %>% pull(SL)), na.rm = T) low_f <- min(as.numeric(data %>% filter(sex_stage == \"F\") %>% pull(SL)), na.rm = T) hi_m <- max(as.numeric(data %>% filter(sex_stage == \"M\") %>% pull(SL)), na.rm = T) hi_i <- max(as.numeric(data %>% filter(sex_stage == \"I\") %>% pull(SL)), na.rm = T)  pred_mock %<>%   filter(sex_stage == \"I\" & SL < hi_i |            sex_stage == \"F\" & SL > low_f |            sex_stage == \"M\" & SL > low_m & SL < hi_m) %>%   mutate(treatment = plyr::mapvalues(pool_density,                                      c(-0.5, 0, 0.5),                                      c(\"decreased\", \"control\", \"increased\")),          treatment = factor(treatment, levels = c(\"decreased\", \"control\", \"increased\")),          sex = plyr::mapvalues(sex_stage,                                c(\"I\", \"M\", \"F\"),                                c(\"immature\", \"males\", \"females\")))        # plotting hcp <- ggplot(pred_mock, aes(x = SL, y = probability, colour = sex)) +   geom_line() +   ylim(0,1) + xlab(\"standard length (mm)\") +   scale_color_manual(values = c(\"#1E88E5\", \"#FFC107\", \"#004D40\")) +   facet_grid(habitat ~ treatment, scales = \"free\", labeller = labeller(habitat = hablab())) +   theme_bw()  hcp jpeg(file.path(here::here(), \"vignettes\", \"figures\", \"habitat_choice.jpeg\"),      width = 8, height = 6, units = \"in\", res = 400) hcp dev.off() ## agg_png  ##       2"},{"path":"https://sebastianodebona.github.io/guppyDme/articles/DME-035_DD_habitat_use.html","id":"ignoring-sex","dir":"Articles","previous_headings":"Analysis","what":"Ignoring sex?","title":"Density-dependent habitat use","text":"results previous show remarkable consistency among different sexes, whilst variation seem nudged size. run similar model , ignoring sex_stage. model including sex much better fit, ’ll plot visualize results anyways.","code":"dcmodel_sexless <- mlogit(choice ~ ba | SL * pool_density, data_mlogit, reflevel = \"A\") summary(dcmodel_sexless) ##  ## Call: ## mlogit(formula = choice ~ ba | SL * pool_density, data = data_mlogit,  ##     reflevel = \"A\", method = \"nr\") ##  ## Frequencies of alternatives:choice ##        A        B        C        D        E  ## 0.139734 0.142586 0.503327 0.148289 0.066065  ##  ## nr method ## 6 iterations, 0h:0m:0s  ## g'(-H)^-1g = 4.19E-05  ## successive function values within tolerance limits  ##  ## Coefficients : ##                 Estimate Std. Error  z-value  Pr(>|z|)     ## (Intercept):B   4.643271   0.326871  14.2052 < 2.2e-16 *** ## (Intercept):C   3.064061   0.265558  11.5382 < 2.2e-16 *** ## (Intercept):D   7.196296   0.381254  18.8753 < 2.2e-16 *** ## (Intercept):E   3.135687   0.384317   8.1591 4.441e-16 *** ## ba              2.522109   0.232028  10.8699 < 2.2e-16 *** ## SL:B           -0.287397   0.020177 -14.2439 < 2.2e-16 *** ## SL:C           -0.123616   0.013827  -8.9404 < 2.2e-16 *** ## SL:D           -0.471721   0.027866 -16.9284 < 2.2e-16 *** ## SL:E           -0.206868   0.023638  -8.7516 < 2.2e-16 *** ## pool_density:B -2.779382   1.261758  -2.2028   0.02761 *   ## pool_density:C -2.444741   1.036089  -2.3596   0.01830 *   ## pool_density:D  4.218638   1.893560   2.2279   0.02589 *   ## pool_density:E  1.888220   2.093610   0.9019   0.36711     ## SL:B            0.103055   0.077567   1.3286   0.18398     ## SL:C            0.088743   0.053622   1.6550   0.09793 .   ## SL:D           -0.365280   0.143431  -2.5467   0.01087 *   ## SL:E           -0.059210   0.125880  -0.4704   0.63809     ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## Log-Likelihood: -2226.6 ## McFadden R^2:  0.22233  ## Likelihood ratio test : chisq = 1273.1 (p.value = < 2.22e-16) AIC(dcmodel_sexless, dcmodel) ##                 df      AIC ## dcmodel_sexless 17 4487.120 ## dcmodel         49 4455.028 # removing sex-stage variable mock_sexless <- mock_d %>%   filter(sex_stage == \"I\") %>%   select(-sex_stage)  # generating predictions pred_mock_sexless <- cbind(block %>% filter(sex_stage == \"I\") %>% select(-sex_stage),                            predict(dcmodel_sexless, newdata = mock_sexless, type = \"probs\"))    # reshaping pred_mock_sexless %<>%   gather(A, B, C, D, E, key = habitat, value = probability) %>%   mutate(density = plyr::mapvalues(pool_density,                                    c(-0.5, 0, 0.5),                                    c(\"decreased\", \"control\", \"increased\")),          density = factor(density, levels = c(\"decreased\", \"control\", \"increased\")))  # plotting ggplot(pred_mock_sexless, aes(x = SL, y = probability)) +   geom_line(aes(linetype = density)) +   scale_linetype_manual(values=c(\"solid\", \"dashed\", \"dotted\")) +   facet_grid(habitat ~., scales = \"free\", labeller = labeller(habitat = hablab())) +   ggtitle(\"Predictions of habitat use\")"},{"path":"https://sebastianodebona.github.io/guppyDme/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Seba De Bona. Author, maintainer. Matthieu Bruneaux. Author. Andrés López-Sepulcre. Author.","code":""},{"path":"https://sebastianodebona.github.io/guppyDme/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"De Bona S, Bruneaux M, López-Sepulcre (2024). guppyDme: Density manipulation experiment wild guppy populations. R package version 1.0.0, https://sebastianodebona.github.io/guppyDme/.","code":"@Manual{,   title = {guppyDme: Density manipulation experiment with wild guppy populations},   author = {Seba {De Bona} and Matthieu Bruneaux and Andrés López-Sepulcre},   year = {2024},   note = {R package version 1.0.0},   url = {https://sebastianodebona.github.io/guppyDme/}, }"},{"path":"https://sebastianodebona.github.io/guppyDme/index.html","id":"density-manipulation-experiment","dir":"","previous_headings":"","what":"Density manipulation experiment with wild guppy populations","title":"Density manipulation experiment with wild guppy populations","text":"project analyzes data Density Manipulation Experiment conducted Trinidad 2018, study effect population density perturbations dispersal habitat use, using natural populations guppies study system. project constitutes part Sebastiano De Bona’s PhD thesis. analysis can reproduced cloning project going manually vignettes, order; installing package guppyDME running pkgdown::build_site() run vignettes . output analyses can seen : Link","code":""},{"path":"https://sebastianodebona.github.io/guppyDme/index.html","id":"how-to-clone-this-project-locally","dir":"","previous_headings":"","what":"How to clone this project locally","title":"Density manipulation experiment with wild guppy populations","text":"access GitHub repository, can clone project remotely opening terminal typing:","code":"git clone"},{"path":"https://sebastianodebona.github.io/guppyDme/index.html","id":"how-to-prepare-your-r-for-the-analyses","dir":"","previous_headings":"","what":"How to prepare your R for the analyses","title":"Density manipulation experiment with wild guppy populations","text":"preparation step required analyses, entails installing list required packages. Copy-paste following code R RStudio execute:","code":"install.packages(c('car', 'devtools', 'FactoMineR', 'factoextra', 'ggplot2', 'ggpubr', 'here', 'knitr', 'lme4', 'lmerTest', 'lubridate', 'magrittr', 'mlogit', 'pkgdown', 'plyr', 'rmarkdown', 'roxygen2', 'rtf', 'scales', 'stargazer', 'tidyverse'))"},{"path":"https://sebastianodebona.github.io/guppyDme/index.html","id":"data","dir":"","previous_headings":"","what":"Data","title":"Density manipulation experiment with wild guppy populations","text":"package comes two datafiles attached: DMEdata.Rda DMEhabitat.Rda.","code":""}]
